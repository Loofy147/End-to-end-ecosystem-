# attention_es_large.py
# نسخة جاهزة للتشغيل على Colab / جهاز قوي
import numpy as np, pandas as pd, matplotlib.pyplot as plt, time, os
np.random.seed(123)

# Function to compute eigenvector centrality-style score (principal eigenvector of |W|)
def centrality_from_A(A):
    M = np.abs(A)
    # add small epsilon to avoid zero matrix issues
    A_prime = M + 1e-8
    # Calculate eigenvalues and eigenvectors
    vals, vecs = np.linalg.eig(A_prime)
    # Find the index of the largest real eigenvalue
    idx = np.argmax(np.real(vals))
    # Get the corresponding eigenvector
    v = np.real(vecs[:, idx])
    # Normalize the eigenvector
    if np.allclose(v,0):
        return np.ones(len(v))/len(v)
    v = np.abs(v)
    v = v / np.max(v) # Normalize to max 1
    return v


# Function to compute network entropy based on connection weights
# Using a simplified approach: entropy of normalized row sums
def network_entropy(A):
    row_sums = A.sum(axis=1)
    total_sum = row_sums.sum()
    if total_sum == 0:
        return 0.0 # Handle empty networks
    # Normalize row sums to get a probability distribution
    probs = row_sums / total_sum
    # Calculate entropy (using natural logarithm)
    # Avoid log(0) by adding a small epsilon or filtering
    entropy_val = -np.sum(probs * np.log(probs + 1e-9))
    return entropy_val


# Function to compute a robustness metric (example placeholder)
# This is a simplified placeholder. A real robustness metric would be complex.
# Example: Could be related to average path length, or resistance to malicious attacks.
def compute_robustness(A, malicious_idx, t):
    # Simplified example: inversely related to the average influence of malicious nodes
    if malicious_idx.size == 0:
        return 1.0 # Perfectly robust if no malicious nodes

    # Calculate average outgoing influence from malicious nodes
    avg_malicious_influence = A[malicious_idx, :].mean()

    # Inversely related to this influence (higher influence means lower robustness)
    # Add a small constant to avoid division by zero or very large values
    robustness_val = 1.0 / (avg_malicious_influence + 1e-6)

    # Optional: Could also consider impact of malicious attacks over time 't'
    # For now, a simple structural metric based on A and malicious_idx

    # Normalize robustness (example: scale between 0 and 1, needs actual bounds)
    # This normalization is highly dependent on the specific metric and expected values.
    # Without domain knowledge, this is a crude example.
    normalized_robustness = np.tanh(robustness_val) # Example non-linear scaling

    return normalized_robustness


# --- Composite Objective Function for ES ---
# Combines multiple metrics into a single score for ES evaluation
# Note: Weights and normalization factors need tuning based on desired system behavior
def compute_composite_objective(S, energy, network_entropy_val, avg_centrality, robustness_val, w_S, w_energy, N_scen): # Added N_scen as argument
    # Normalize energy cost (example: simple scaling based on N or total possible energy)
    # Total possible energy is approx N_scen*N_scen*max_weight_per_connection (e.g., 0.05)
    # A better normalization would be based on the distribution of energy values observed.
    max_possible_energy_rough = N_scen * N_scen * 0.05
    normalized_energy_cost = energy / (max_possible_energy_rough + 1e-9)

    # Normalize network entropy (example: scale by max possible entropy for N nodes, log(N))
    max_possible_entropy = np.log(N_scen) # Max entropy for a uniform distribution
    normalized_entropy = network_entropy_val / (max_possible_entropy + 1e-9)

    # Normalize centrality (already normalized to max 1 by centrality_from_A)
    normalized_centrality = avg_centrality

    # Robustness is assumed to be already normalized (e.g., 0-1) by compute_robustness

    # Define weights for each component in the composite score
    # These weights are crucial and require tuning
    weight_S = w_S * 1.0 # Weight for cohesion (S) - using w_S from config as base
    weight_energy_cost = w_energy * 10.0 # Weight for normalized energy cost (negative)
    weight_entropy = 0.1 # Weight for normalized network entropy (higher entropy preferred)
    weight_centrality = 0.2 # Weight for average centrality (can be positive or negative depending on goal)
    weight_robustness = 0.5 # Weight for robustness (higher robustness preferred)


    # Calculate the composite score
    composite_score = (
        weight_S * S
        - weight_energy_cost * normalized_energy_cost
        + weight_entropy * normalized_entropy
        + weight_centrality * normalized_centrality
        + weight_robustness * robustness_val
    )

    return composite_score
# --- End Composite Objective Function ---



# Function to compute eigenvector centrality-style score (principal eigenvector of |W|)
def centrality_from_A(A):
    M = np.abs(A)
    # add small epsilon to avoid zero matrix issues
    A_prime = M + 1e-8
    # Calculate eigenvalues and eigenvectors
    vals, vecs = np.linalg.eig(A_prime)
    # Find the index of the largest real eigenvalue
    idx = np.argmax(np.real(vals))
    # Get the corresponding eigenvector
    v = np.real(vecs[:, idx])
    # Normalize the eigenvector
    if np.allclose(v,0):
        return np.ones(len(v))/len(v)
    v = np.abs(v)
    v = v / np.max(v) # Normalize to max 1
    return v


# Function to compute network entropy based on connection weights
# Using a simplified approach: entropy of normalized row sums
def network_entropy(A):
    row_sums = A.sum(axis=1)
    total_sum = row_sums.sum()
    if total_sum == 0:
        return 0.0 # Handle empty networks
    # Normalize row sums to get a probability distribution
    probs = row_sums / total_sum
    # Calculate entropy (using natural logarithm)
    # Avoid log(0) by adding a small epsilon or filtering
    entropy_val = -np.sum(probs * np.log(probs + 1e-9))
    return entropy_val


# Function to compute a robustness metric (example placeholder)
# This is a simplified placeholder. A real robustness metric would be complex.
# Example: Could be related to average path length, or resistance to malicious attacks.
def compute_robustness(A, malicious_idx, t):
    # Simplified example: inversely related to the average influence of malicious nodes
    if malicious_idx.size == 0:
        return 1.0 # Perfectly robust if no malicious nodes

    # Calculate average outgoing influence from malicious nodes
    avg_malicious_influence = A[malicious_idx, :].mean()

    # Inversely related to this influence (higher influence means lower robustness)
    # Add a small constant to avoid division by zero or very large values
    robustness_val = 1.0 / (avg_malicious_influence + 1e-6)

    # Optional: Could also consider impact of malicious attacks over time 't'
    # For now, a simple structural metric based on A and malicious_idx

    # Normalize robustness (example: scale between 0 and 1, needs actual bounds)
    # This normalization is highly dependent on the specific metric and expected values.
    # Without domain knowledge, this is a crude example.
    normalized_robustness = np.tanh(robustness_val) # Example non-linear scaling

    return normalized_robustness


# --- Composite Objective Function for ES ---
# Combines multiple metrics into a single score for ES evaluation
# Note: Weights and normalization factors need tuning based on desired system behavior
def compute_composite_objective(S, energy, network_entropy_val, avg_centrality, robustness_val, w_S, w_energy, N_scen): # Added N_scen as argument
    # Normalize energy cost (example: simple scaling based on N or total possible energy)
    # Total possible energy is approx N_scen*N_scen*max_weight_per_connection (e.g., 0.05)
    # A better normalization would be based on the distribution of energy values observed.
    max_possible_energy_rough = N_scen * N_scen * 0.05
    normalized_energy_cost = energy / (max_possible_energy_rough + 1e-9)

    # Normalize network entropy (example: scale by max possible entropy for N nodes, log(N))
    max_possible_entropy = np.log(N_scen) # Max entropy for a uniform distribution
    normalized_entropy = network_entropy_val / (max_possible_entropy + 1e-9)

    # Normalize centrality (already normalized to max 1 by centrality_from_A)
    normalized_centrality = avg_centrality

    # Robustness is assumed to be already normalized (e.g., 0-1) by compute_robustness

    # Define weights for each component in the composite score
    # These weights are crucial and require tuning
    weight_S = w_S * 1.0 # Weight for cohesion (S) - using w_S from config as base
    weight_energy_cost = w_energy * 10.0 # Weight for normalized energy cost (negative)
    weight_entropy = 0.1 # Weight for normalized network entropy (higher entropy preferred)
    weight_centrality = 0.2 # Weight for average centrality (can be positive or negative depending on goal)
    weight_robustness = 0.5 # Weight for robustness (higher robustness preferred)


    # Calculate the composite score
    composite_score = (
        weight_S * S
        - weight_energy_cost * normalized_energy_cost
        + weight_entropy * normalized_entropy
        + weight_centrality * normalized_centrality
        + weight_robustness * robustness_val
    )

    return composite_score
# --- End Composite Objective Function ---



# Function to compute eigenvector centrality-style score (principal eigenvector of |W|)
def centrality_from_A(A):
    M = np.abs(A)
    # add small epsilon to avoid zero matrix issues
    A_prime = M + 1e-8
    # Calculate eigenvalues and eigenvectors
    vals, vecs = np.linalg.eig(A_prime)
    # Find the index of the largest real eigenvalue
    idx = np.argmax(np.real(vals))
    # Get the corresponding eigenvector
    v = np.real(vecs[:, idx])
    # Normalize the eigenvector
    if np.allclose(v,0):
        return np.ones(len(v))/len(v)
    v = np.abs(v)
    v = v / np.max(v) # Normalize to max 1
    return v


# Function to compute network entropy based on connection weights
# Using a simplified approach: entropy of normalized row sums
def network_entropy(A):
    row_sums = A.sum(axis=1)
    total_sum = row_sums.sum()
    if total_sum == 0:
        return 0.0 # Handle empty networks
    # Normalize row sums to get a probability distribution
    probs = row_sums / total_sum
    # Calculate entropy (using natural logarithm)
    # Avoid log(0) by adding a small epsilon or filtering
    entropy_val = -np.sum(probs * np.log(probs + 1e-9))
    return entropy_val


# Function to compute a robustness metric (example placeholder)
# This is a simplified placeholder. A real robustness metric would be complex.
# Example: Could be related to average path length, or resistance to malicious attacks.
def compute_robustness(A, malicious_idx, t):
    # Simplified example: inversely related to the average influence of malicious nodes
    if malicious_idx.size == 0:
        return 1.0 # Perfectly robust if no malicious nodes

    # Calculate average outgoing influence from malicious nodes
    avg_malicious_influence = A[malicious_idx, :].mean()

    # Inversely related to this influence (higher influence means lower robustness)
    # Add a small constant to avoid division by zero or very large values
    robustness_val = 1.0 / (avg_malicious_influence + 1e-6)

    # Optional: Could also consider impact of malicious attacks over time 't'
    # For now, a simple structural metric based on A and malicious_idx

    # Normalize robustness (example: scale between 0 and 1, needs actual bounds)
    # This normalization is highly dependent on the specific metric and expected values.
    # Without domain knowledge, this is a crude example.
    normalized_robustness = np.tanh(robustness_val) # Example non-linear scaling

    return normalized_robustness


# --- Composite Objective Function for ES ---
# Combines multiple metrics into a single score for ES evaluation
# Note: Weights and normalization factors need tuning based on desired system behavior
def compute_composite_objective(S, energy, network_entropy_val, avg_centrality, robustness_val, w_S, w_energy, N_scen): # Added N_scen as argument
    # Normalize energy cost (example: simple scaling based on N or total possible energy)
    # Total possible energy is approx N_scen*N_scen*max_weight_per_connection (e.g., 0.05)
    # A better normalization would be based on the distribution of energy values observed.
    max_possible_energy_rough = N_scen * N_scen * 0.05
    normalized_energy_cost = energy / (max_possible_energy_rough + 1e-9)

    # Normalize network entropy (example: scale by max possible entropy for N nodes, log(N))
    max_possible_entropy = np.log(N_scen) # Max entropy for a uniform distribution
    normalized_entropy = network_entropy_val / (max_possible_entropy + 1e-9)

    # Normalize centrality (already normalized to max 1 by centrality_from_A)
    normalized_centrality = avg_centrality

    # Robustness is assumed to be already normalized (e.g., 0-1) by compute_robustness

    # Define weights for each component in the composite score
    # These weights are crucial and require tuning
    weight_S = w_S * 1.0 # Weight for cohesion (S) - using w_S from config as base
    weight_energy_cost = w_energy * 10.0 # Weight for normalized energy cost (negative)
    weight_entropy = 0.1 # Weight for normalized network entropy (higher entropy preferred)
    weight_centrality = 0.2 # Weight for average centrality (can be positive or negative depending on goal)
    weight_robustness = 0.5 # Weight for robustness (higher robustness preferred)


    # Calculate the composite score
    composite_score = (
        weight_S * S
        - weight_energy_cost * normalized_energy_cost
        + weight_entropy * normalized_entropy
        + weight_centrality * normalized_centrality
        + weight_robustness * robustness_val
    )

    return composite_score
# --- End Composite Objective Function ---



# Function to compute eigenvector centrality-style score (principal eigenvector of |W|)
def centrality_from_A(A):
    M = np.abs(A)
    # add small epsilon to avoid zero matrix issues
    A_prime = M + 1e-8
    # Calculate eigenvalues and eigenvectors
    vals, vecs = np.linalg.eig(A_prime)
    # Find the index of the largest real eigenvalue
    idx = np.argmax(np.real(vals))
    # Get the corresponding eigenvector
    v = np.real(vecs[:, idx])
    # Normalize the eigenvector
    if np.allclose(v,0):
        return np.ones(len(v))/len(v)
    v = np.abs(v)
    v = v / np.max(v) # Normalize to max 1
    return v


# Function to compute network entropy based on connection weights
# Using a simplified approach: entropy of normalized row sums
def network_entropy(A):
    row_sums = A.sum(axis=1)
    total_sum = row_sums.sum()
    if total_sum == 0:
        return 0.0 # Handle empty networks
    # Normalize row sums to get a probability distribution
    probs = row_sums / total_sum
    # Calculate entropy (using natural logarithm)
    # Avoid log(0) by adding a small epsilon or filtering
    entropy_val = -np.sum(probs * np.log(probs + 1e-9))
    return entropy_val


# Function to compute a robustness metric (example placeholder)
# This is a simplified placeholder. A real robustness metric would be complex.
# Example: Could be related to average path length, or resistance to malicious attacks.
def compute_robustness(A, malicious_idx, t):
    # Simplified example: inversely related to the average influence of malicious nodes
    if malicious_idx.size == 0:
        return 1.0 # Perfectly robust if no malicious nodes

    # Calculate average outgoing influence from malicious nodes
    avg_malicious_influence = A[malicious_idx, :].mean()

    # Inversely related to this influence (higher influence means lower robustness)
    # Add a small constant to avoid division by zero or very large values
    robustness_val = 1.0 / (avg_malicious_influence + 1e-6)

    # Optional: Could also consider impact of malicious attacks over time 't'
    # For now, a simple structural metric based on A and malicious_idx

    # Normalize robustness (example: scale between 0 and 1, needs actual bounds)
    # This normalization is highly dependent on the specific metric and expected values.
    # Without domain knowledge, this is a crude example.
    normalized_robustness = np.tanh(robustness_val) # Example non-linear scaling

    return normalized_robustness


# --- Composite Objective Function for ES ---
# Combines multiple metrics into a single score for ES evaluation
# Note: Weights and normalization factors need tuning based on desired system behavior
def compute_composite_objective(S, energy, network_entropy_val, avg_centrality, robustness_val, w_S, w_energy, N_scen): # Added N_scen as argument
    # Normalize energy cost (example: simple scaling based on N or total possible energy)
    # Total possible energy is approx N_scen*N_scen*max_weight_per_connection (e.g., 0.05)
    # A better normalization would be based on the distribution of energy values observed.
    max_possible_energy_rough = N_scen * N_scen * 0.05
    normalized_energy_cost = energy / (max_possible_energy_rough + 1e-9)

    # Normalize network entropy (example: scale by max possible entropy for N nodes, log(N))
    max_possible_entropy = np.log(N_scen) # Max entropy for a uniform distribution
    normalized_entropy = network_entropy_val / (max_possible_entropy + 1e-9)

    # Normalize centrality (already normalized to max 1 by centrality_from_A)
    normalized_centrality = avg_centrality

    # Robustness is assumed to be already normalized (e.g., 0-1) by compute_robustness

    # Define weights for each component in the composite score
    # These weights are crucial and require tuning
    weight_S = w_S * 1.0 # Weight for cohesion (S) - using w_S from config as base
    weight_energy_cost = w_energy * 10.0 # Weight for normalized energy cost (negative)
    weight_entropy = 0.1 # Weight for normalized network entropy (higher entropy preferred)
    weight_centrality = 0.2 # Weight for average centrality (can be positive or negative depending on goal)
    weight_robustness = 0.5 # Weight for robustness (higher robustness preferred)


    # Calculate the composite score
    composite_score = (
        weight_S * S
        - weight_energy_cost * normalized_energy_cost
        + weight_entropy * normalized_entropy
        + weight_centrality * normalized_centrality
        + weight_robustness * robustness_val
    )

    return composite_score
# --- End Composite Objective Function ---



# Function to compute eigenvector centrality-style score (principal eigenvector of |W|)
def centrality_from_A(A):
    M = np.abs(A)
    # add small epsilon to avoid zero matrix issues
    A_prime = M + 1e-8
    # Calculate eigenvalues and eigenvectors
    vals, vecs = np.linalg.eig(A_prime)
    # Find the index of the largest real eigenvalue
    idx = np.argmax(np.real(vals))
    # Get the corresponding eigenvector
    v = np.real(vecs[:, idx])
    # Normalize the eigenvector
    if np.allclose(v,0):
        return np.ones(len(v))/len(v)
    v = np.abs(v)
    v = v / np.max(v) # Normalize to max 1
    return v


# Function to compute network entropy based on connection weights
# Using a simplified approach: entropy of normalized row sums
def network_entropy(A):
    row_sums = A.sum(axis=1)
    total_sum = row_sums.sum()
    if total_sum == 0:
        return 0.0 # Handle empty networks
    # Normalize row sums to get a probability distribution
    probs = row_sums / total_sum
    # Calculate entropy (using natural logarithm)
    # Avoid log(0) by adding a small epsilon or filtering
    entropy_val = -np.sum(probs * np.log(probs + 1e-9))
    return entropy_val


# Function to compute a robustness metric (example placeholder)
# This is a simplified placeholder. A real robustness metric would be complex.
# Example: Could be related to average path length, or resistance to malicious attacks.
def compute_robustness(A, malicious_idx, t):
    # Simplified example: inversely related to the average influence of malicious nodes
    if malicious_idx.size == 0:
        return 1.0 # Perfectly robust if no malicious nodes

    # Calculate average outgoing influence from malicious nodes
    avg_malicious_influence = A[malicious_idx, :].mean()

    # Inversely related to this influence (higher influence means lower robustness)
    # Add a small constant to avoid division by zero or very large values
    robustness_val = 1.0 / (avg_malicious_influence + 1e-6)

    # Optional: Could also consider impact of malicious attacks over time 't'
    # For now, a simple structural metric based on A and malicious_idx

    # Normalize robustness (example: scale between 0 and 1, needs actual bounds)
    # This normalization is highly dependent on the specific metric and expected values.
    # Without domain knowledge, this is a crude example.
    normalized_robustness = np.tanh(robustness_val) # Example non-linear scaling

    return normalized_robustness


# --- Composite Objective Function for ES ---
# Combines multiple metrics into a single score for ES evaluation
# Note: Weights and normalization factors need tuning based on desired system behavior
def compute_composite_objective(S, energy, network_entropy_val, avg_centrality, robustness_val, w_S, w_energy, N_scen): # Added N_scen as argument
    # Normalize energy cost (example: simple scaling based on N or total possible energy)
    # Total possible energy is approx N_scen*N_scen*max_weight_per_connection (e.g., 0.05)
    # A better normalization would be based on the distribution of energy values observed.
    max_possible_energy_rough = N_scen * N_scen * 0.05
    normalized_energy_cost = energy / (max_possible_energy_rough + 1e-9)

    # Normalize network entropy (example: scale by max possible entropy for N nodes, log(N))
    max_possible_entropy = np.log(N_scen) # Max entropy for a uniform distribution
    normalized_entropy = network_entropy_val / (max_possible_entropy + 1e-9)

    # Normalize centrality (already normalized to max 1 by centrality_from_A)
    normalized_centrality = avg_centrality

    # Robustness is assumed to be already normalized (e.g., 0-1) by compute_robustness

    # Define weights for each component in the composite score
    # These weights are crucial and require tuning
    weight_S = w_S * 1.0 # Weight for cohesion (S) - using w_S from config as base
    weight_energy_cost = w_energy * 10.0 # Weight for normalized energy cost (negative)
    weight_entropy = 0.1 # Weight for normalized network entropy (higher entropy preferred)
    weight_centrality = 0.2 # Weight for average centrality (can be positive or negative depending on goal)
    weight_robustness = 0.5 # Weight for robustness (higher robustness preferred)


    # Calculate the composite score
    composite_score = (
        weight_S * S
        - weight_energy_cost * normalized_energy_cost
        + weight_entropy * normalized_entropy
        + weight_centrality * normalized_centrality
        + weight_robustness * robustness_val
    )

    return composite_score
# --- End Composite Objective Function ---



# Function to compute eigenvector centrality-style score (principal eigenvector of |W|)
def centrality_from_A(A):
    M = np.abs(A)
    # add small epsilon to avoid zero matrix issues
    A_prime = M + 1e-8
    # Calculate eigenvalues and eigenvectors
    vals, vecs = np.linalg.eig(A_prime)
    # Find the index of the largest real eigenvalue
    idx = np.argmax(np.real(vals))
    # Get the corresponding eigenvector
    v = np.real(vecs[:, idx])
    # Normalize the eigenvector
    if np.allclose(v,0):
        return np.ones(len(v))/len(v)
    v = np.abs(v)
    v = v / np.max(v) # Normalize to max 1
    return v


# Function to compute network entropy based on connection weights
# Using a simplified approach: entropy of normalized row sums
def network_entropy(A):
    row_sums = A.sum(axis=1)
    total_sum = row_sums.sum()
    if total_sum == 0:
        return 0.0 # Handle empty networks
    # Normalize row sums to get a probability distribution
    probs = row_sums / total_sum
    # Calculate entropy (using natural logarithm)
    # Avoid log(0) by adding a small epsilon or filtering
    entropy_val = -np.sum(probs * np.log(probs + 1e-9))
    return entropy_val


# Function to compute a robustness metric (example placeholder)
# This is a simplified placeholder. A real robustness metric would be complex.
# Example: Could be related to average path length, or resistance to malicious attacks.
def compute_robustness(A, malicious_idx, t):
    # Simplified example: inversely related to the average influence of malicious nodes
    if malicious_idx.size == 0:
        return 1.0 # Perfectly robust if no malicious nodes

    # Calculate average outgoing influence from malicious nodes
    avg_malicious_influence = A[malicious_idx, :].mean()

    # Inversely related to this influence (higher influence means lower robustness)
    # Add a small constant to avoid division by zero or very large values
    robustness_val = 1.0 / (avg_malicious_influence + 1e-6)

    # Optional: Could also consider impact of malicious attacks over time 't'
    # For now, a simple structural metric based on A and malicious_idx

    # Normalize robustness (example: scale between 0 and 1, needs actual bounds)
    # This normalization is highly dependent on the specific metric and expected values.
    # Without domain knowledge, this is a crude example.
    normalized_robustness = np.tanh(robustness_val) # Example non-linear scaling

    return normalized_robustness


# --- Composite Objective Function for ES ---
# Combines multiple metrics into a single score for ES evaluation
# Note: Weights and normalization factors need tuning based on desired system behavior
def compute_composite_objective(S, energy, network_entropy_val, avg_centrality, robustness_val, w_S, w_energy, N_scen): # Added N_scen as argument
    # Normalize energy cost (example: simple scaling based on N or total possible energy)
    # Total possible energy is approx N_scen*N_scen*max_weight_per_connection (e.g., 0.05)
    # A better normalization would be based on the distribution of energy values observed.
    max_possible_energy_rough = N_scen * N_scen * 0.05
    normalized_energy_cost = energy / (max_possible_energy_rough + 1e-9)

    # Normalize network entropy (example: scale by max possible entropy for N nodes, log(N))
    max_possible_entropy = np.log(N_scen) # Max entropy for a uniform distribution
    normalized_entropy = network_entropy_val / (max_possible_entropy + 1e-9)

    # Normalize centrality (already normalized to max 1 by centrality_from_A)
    normalized_centrality = avg_centrality

    # Robustness is assumed to be already normalized (e.g., 0-1) by compute_robustness

    # Define weights for each component in the composite score
    # These weights are crucial and require tuning
    weight_S = w_S * 1.0 # Weight for cohesion (S) - using w_S from config as base
    weight_energy_cost = w_energy * 10.0 # Weight for normalized energy cost (negative)
    weight_entropy = 0.1 # Weight for normalized network entropy (higher entropy preferred)
    weight_centrality = 0.2 # Weight for average centrality (can be positive or negative depending on goal)
    weight_robustness = 0.5 # Weight for robustness (higher robustness preferred)


    # Calculate the composite score
    composite_score = (
        weight_S * S
        - weight_energy_cost * normalized_energy_cost
        + weight_entropy * normalized_entropy
        + weight_centrality * normalized_centrality
        + weight_robustness * robustness_val
    )

    return composite_score
# --- End Composite Objective Function ---



# Function to compute eigenvector centrality-style score (principal eigenvector of |W|)
def centrality_from_A(A):
    M = np.abs(A)
    # add small epsilon to avoid zero matrix issues
    A_prime = M + 1e-8
    # Calculate eigenvalues and eigenvectors
    vals, vecs = np.linalg.eig(A_prime)
    # Find the index of the largest real eigenvalue
    idx = np.argmax(np.real(vals))
    # Get the corresponding eigenvector
    v = np.real(vecs[:, idx])
    # Normalize the eigenvector
    if np.allclose(v,0):
        return np.ones(len(v))/len(v)
    v = np.abs(v)
    v = v / np.max(v) # Normalize to max 1
    return v


# Function to compute network entropy based on connection weights
# Using a simplified approach: entropy of normalized row sums
def network_entropy(A):
    row_sums = A.sum(axis=1)
    total_sum = row_sums.sum()
    if total_sum == 0:
        return 0.0 # Handle empty networks
    # Normalize row sums to get a probability distribution
    probs = row_sums / total_sum
    # Calculate entropy (using natural logarithm)
    # Avoid log(0) by adding a small epsilon or filtering
    entropy_val = -np.sum(probs * np.log(probs + 1e-9))
    return entropy_val


# Function to compute a robustness metric (example placeholder)
# This is a simplified placeholder. A real robustness metric would be complex.
# Example: Could be related to average path length, or resistance to malicious attacks.
def compute_robustness(A, malicious_idx, t):
    # Simplified example: inversely related to the average influence of malicious nodes
    if malicious_idx.size == 0:
        return 1.0 # Perfectly robust if no malicious nodes

    # Calculate average outgoing influence from malicious nodes
    avg_malicious_influence = A[malicious_idx, :].mean()

    # Inversely related to this influence (higher influence means lower robustness)
    # Add a small constant to avoid division by zero or very large values
    robustness_val = 1.0 / (avg_malicious_influence + 1e-6)

    # Optional: Could also consider impact of malicious attacks over time 't'
    # For now, a simple structural metric based on A and malicious_idx

    # Normalize robustness (example: scale between 0 and 1, needs actual bounds)
    # This normalization is highly dependent on the specific metric and expected values.
    # Without domain knowledge, this is a crude example.
    normalized_robustness = np.tanh(robustness_val) # Example non-linear scaling

    return normalized_robustness


# --- Composite Objective Function for ES ---
# Combines multiple metrics into a single score for ES evaluation
# Note: Weights and normalization factors need tuning based on desired system behavior
def compute_composite_objective(S, energy, network_entropy_val, avg_centrality, robustness_val, w_S, w_energy, N_scen): # Added N_scen as argument
    # Normalize energy cost (example: simple scaling based on N or total possible energy)
    # Total possible energy is approx N_scen*N_scen*max_weight_per_connection (e.g., 0.05)
    # A better normalization would be based on the distribution of energy values observed.
    max_possible_energy_rough = N_scen * N_scen * 0.05
    normalized_energy_cost = energy / (max_possible_energy_rough + 1e-9)

    # Normalize network entropy (example: scale by max possible entropy for N nodes, log(N))
    max_possible_entropy = np.log(N_scen) # Max entropy for a uniform distribution
    normalized_entropy = network_entropy_val / (max_possible_entropy + 1e-9)

    # Normalize centrality (already normalized to max 1 by centrality_from_A)
    normalized_centrality = avg_centrality

    # Robustness is assumed to be already normalized (e.g., 0-1) by compute_robustness

    # Define weights for each component in the composite score
    # These weights are crucial and require tuning
    weight_S = w_S * 1.0 # Weight for cohesion (S) - using w_S from config as base
    weight_energy_cost = w_energy * 10.0 # Weight for normalized energy cost (negative)
    weight_entropy = 0.1 # Weight for normalized network entropy (higher entropy preferred)
    weight_centrality = 0.2 # Weight for average centrality (can be positive or negative depending on goal)
    weight_robustness = 0.5 # Weight for robustness (higher robustness preferred)


    # Calculate the composite score
    composite_score = (
        weight_S * S
        - weight_energy_cost * normalized_energy_cost
        + weight_entropy * normalized_entropy
        + weight_centrality * normalized_centrality
        + weight_robustness * robustness_val
    )

    return composite_score
# --- End Composite Objective Function ---



# Function to compute eigenvector centrality-style score (principal eigenvector of |W|)
def centrality_from_A(A):
    M = np.abs(A)
    # add small epsilon to avoid zero matrix issues
    A_prime = M + 1e-8
    # Calculate eigenvalues and eigenvectors
    vals, vecs = np.linalg.eig(A_prime)
    # Find the index of the largest real eigenvalue
    idx = np.argmax(np.real(vals))
    # Get the corresponding eigenvector
    v = np.real(vecs[:, idx])
    # Normalize the eigenvector
    if np.allclose(v,0):
        return np.ones(len(v))/len(v)
    v = np.abs(v)
    v = v / np.max(v) # Normalize to max 1
    return v


# Function to compute network entropy based on connection weights
# Using a simplified approach: entropy of normalized row sums
def network_entropy(A):
    row_sums = A.sum(axis=1)
    total_sum = row_sums.sum()
    if total_sum == 0:
        return 0.0 # Handle empty networks
    # Normalize row sums to get a probability distribution
    probs = row_sums / total_sum
    # Calculate entropy (using natural logarithm)
    # Avoid log(0) by adding a small epsilon or filtering
    entropy_val = -np.sum(probs * np.log(probs + 1e-9))
    return entropy_val


# Function to compute a robustness metric (example placeholder)
# This is a simplified placeholder. A real robustness metric would be complex.
# Example: Could be related to average path length, or resistance to malicious attacks.
def compute_robustness(A, malicious_idx, t):
    # Simplified example: inversely related to the average influence of malicious nodes
    if malicious_idx.size == 0:
        return 1.0 # Perfectly robust if no malicious nodes

    # Calculate average outgoing influence from malicious nodes
    avg_malicious_influence = A[malicious_idx, :].mean()

    # Inversely related to this influence (higher influence means lower robustness)
    # Add a small constant to avoid division by zero or very large values
    robustness_val = 1.0 / (avg_malicious_influence + 1e-6)

    # Optional: Could also consider impact of malicious attacks over time 't'
    # For now, a simple structural metric based on A and malicious_idx

    # Normalize robustness (example: scale between 0 and 1, needs actual bounds)
    # This normalization is highly dependent on the specific metric and expected values.
    # Without domain knowledge, this is a crude example.
    normalized_robustness = np.tanh(robustness_val) # Example non-linear scaling

    return normalized_robustness


# --- Composite Objective Function for ES ---
# Combines multiple metrics into a single score for ES evaluation
# Note: Weights and normalization factors need tuning based on desired system behavior
def compute_composite_objective(S, energy, network_entropy_val, avg_centrality, robustness_val, w_S, w_energy):
    # Normalize energy cost (example: simple scaling based on N or total possible energy)
    # Total possible energy is approx N*N*max_weight_per_connection (e.g., 0.05)
    # A better normalization would be based on the distribution of energy values observed.
    max_possible_energy_rough = N_scen * N_scen * 0.05
    normalized_energy_cost = energy / (max_possible_energy_rough + 1e-9)

    # Normalize network entropy (example: scale by max possible entropy for N nodes, log(N))
    max_possible_entropy = np.log(N_scen) # Max entropy for a uniform distribution
    normalized_entropy = network_entropy_val / (max_possible_entropy + 1e-9)

    # Normalize centrality (already normalized to max 1 by centrality_from_A)
    normalized_centrality = avg_centrality

    # Robustness is assumed to be already normalized (e.g., 0-1) by compute_robustness

    # Define weights for each component in the composite score
    # These weights are crucial and require tuning
    weight_S = w_S * 1.0 # Weight for cohesion (S) - using w_S from config as base
    weight_energy_cost = w_energy * 10.0 # Weight for normalized energy cost (negative)
    weight_entropy = 0.1 # Weight for normalized network entropy (higher entropy preferred)
    weight_centrality = 0.2 # Weight for average centrality (can be positive or negative depending on goal)
    weight_robustness = 0.5 # Weight for robustness (higher robustness preferred)


    # Calculate the composite score
    composite_score = (
        weight_S * S
        - weight_energy_cost * normalized_energy_cost
        + weight_entropy * normalized_entropy
        + weight_centrality * normalized_centrality
        + weight_robustness * robustness_val
    )

    return composite_score
# --- End Composite Objective Function ---



# ---------- تعديل سريع للمعلمات (اضبط هنا) ----------
N = 800                # حجم النظام الكبير المطلوب (ابدأ بـ 200-800 على Colab Pro)
T = 800                # عدد الخطوات الزمنية
alpha = 0.34
init_eta = 0.06
init_lambda = 0.012
noise_sigma = 0.03
energy_cost_per_weight = 1.0
init_gate_topk = 16
intervene_every = 25
es_population = 12
probe_steps = 6
audit_strength = 0.5
malicious_frac = 0.05
w_S = 1.0
w_energy = 0.0045
# -------------------------------------------------------

# --- Fixed Negative Score for Failed Probes ---
fixed_negative_probe_score = -1000.0 # Example value for invalid probes
# --- End Fixed Negative Score ---



# --- Fixed Negative Score for Failed Probes ---
fixed_negative_probe_score = -1000.0 # Example value for invalid probes
# --- End Fixed Negative Score ---



# --- Fixed Negative Score for Failed Probes ---
fixed_negative_probe_score = -1000.0 # Example value for invalid probes
# --- End Fixed Negative Score ---



# --- Fixed Negative Score for Failed Probes ---
fixed_negative_probe_score = -1000.0 # Example value for invalid probes
# --- End Fixed Negative Score ---



# --- Fixed Negative Score for Failed Probes ---
fixed_negative_probe_score = -1000.0 # Example value for invalid probes
# --- End Fixed Negative Score ---



# --- Fixed Negative Score for Failed Probes ---
fixed_negative_probe_score = -1000.0 # Example value for invalid probes
# --- End Fixed Negative Score ---



# --- Parameter Bounds (for ES adaptive controller) ---
min_eta, max_eta = 1e-9, 0.1 # Example bounds for eta
min_lambda, max_lambda = 1e-7, 0.05 # Example bounds for lambda
# min_gate_topk, max_gate_topk needs N_scen, define inside scenario loop
# --- End Parameter Bounds ---


# --- Fixed Negative Score for Failed Probes ---
fixed_negative_probe_score = -1000.0 # Example value for invalid probes
# --- End Fixed Negative Score ---



# --- Parameter Bounds (for ES adaptive controller) ---
min_eta, max_eta = 1e-9, 0.1 # Example bounds for eta
min_lambda, max_lambda = 1e-7, 0.05 # Example bounds for lambda
min_gate_topk, max_gate_topk = 1.0, float(N_scen) # gate_topk should not exceed N_scen
# --- End Parameter Bounds ---


# --- Fixed Negative Score for Failed Probes ---
fixed_negative_probe_score = -1000.0 # Example value for invalid probes
# --- End Fixed Negative Score ---



# ---------- دوال مساعدة (مؤثّرة على الأداء؛ حافظ عليها مُوجزة) ----------
eps = 1e-12
def aggregate_inputs(A, b):
    return (A.T.dot(b)) / (A.sum(axis=0) + eps)

# --- Conceptual Insights: Awareness / State Update Mechanisms (from Arabic files) ---
    # The update_states function determines how node states evolve based on inputs and noise.
    # Ideas about 'awareness' or new state update mechanisms could be explored here.
    # --- End Conceptual Insights Comment ---
def update_states(b, I, alpha, sigma):
    noise = np.random.normal(0, sigma, size=b.shape)
    return np.tanh((1-alpha)*b + alpha*I + noise)

def compute_S(b): return max(-1.0, 1.0 - np.var(b))
def energy_of_A(A): return energy_cost_per_weight * A.sum()

# --- Conceptual Insights: Attention Mechanisms (from Arabic files) ---
# The apply_gating function embodies a form of attention mechanism by selecting top-k connections.
# Concepts from attention theory could inspire alternative gating or weighting strategies.
# --- End Conceptual Insights Comment ---
def apply_gating(A, topk):
    # حفاظًا على الأداء نستخدم argpartition لكل صف
    if topk >= A.shape[1]: return A.copy()
    A2 = np.zeros_like(A)
    for i in range(A.shape[0]):
        row = A[i]
        if row.sum() <= 0: continue
        k = min(topk, row.size)
        idxs = np.argpartition(-row, k-1)[:k]
        A2[i, idxs] = row[idxs]
    return A2
# -------------------------------------------------------

# ---------- التهيئة ----------

# --- Scenario Definitions ---
scenarios = [
    {'name': 'Base Case', 'params': {}}, # Use default parameters
    {'name': 'High Eta', 'params': {'init_eta': 0.1}},
    {'name': 'Low Lambda', 'params': {'init_lambda': 0.005}},
    {'name': 'High Gate TopK', 'params': {'init_gate_topk': 30.0}},
    {'name': 'High Energy Cost', 'params': {'w_energy': 0.01}},
]
# --- End Scenario Definitions ---


# --- Scenario Experimentation Loop ---
scenario_results = {} # To store results from each scenario

for scenario in scenarios:
    print(f"\n--- Running Scenario: {scenario['name']} ---")

    # Apply scenario-specific parameter overrides
    scenario_params = {} # Start with empty params for scenario overrides
    # Add other base parameters you might want to override in scenarios
    scenario_base_params = {
        'N': N, 'T': T, 'alpha': alpha, 'noise_sigma': noise_sigma,
        'energy_cost_per_weight': energy_cost_per_weight, 'audit_strength': audit_strength,
        'malicious_frac': malicious_frac, 'w_S': w_S, 'w_energy': w_energy,
        'intervene_every': intervene_every, 'es_population': es_population, 'probe_steps': probe_steps
    }
    # Use init_eta, init_lambda, init_gate_topk from original config as defaults for ctrl
    ctrl_params = {'eta': init_eta, 'lambda': init_lambda, 'gate_topk': init_gate_topk}

    current_params = {**scenario_base_params, **ctrl_params, **scenario['params']} # Merge defaults, initial ctrl, and scenario overrides


    # --- Re-Initialization for Scenario (---------- التهيئة ----------) ---
    # This section is copied from the original initialization, adapted to use current_params
    N_scen = int(current_params['N'])
    T_scen = int(current_params['T'])
    alpha_scen = current_params['alpha']
    noise_sigma_scen = current_params['noise_sigma']
    energy_cost_per_weight_scen = current_params['energy_cost_per_weight']
    audit_strength_scen = current_params['audit_strength']
    malicious_frac_scen = current_params['malicious_frac']
    w_S_scen = current_params['w_S']
    w_energy_scen = current_params['w_energy']
    intervene_every_scen = int(current_params['intervene_every'])
    es_population_scen = int(current_params['es_population'])
    probe_steps_scen = int(current_params['probe_steps'])

    print(f"  Scenario '{scenario['name']}' - N: {N_scen}, T: {T_scen}, es_pop: {es_population_scen}, probe_steps: {probe_steps_scen}")


    # --- Potential Improvement: More detailed node feature representation and Explicit Agent node (from hard.txt) ---
    # Instead of just a single state value `b` per node, a richer state vector or dictionary
    # could be used for each node, e.g., incorporating concepts like 'position', 'price', etc.
    # An explicit 'agent' node could be defined with its own unique features and update rules.
    # This would require significant changes to how states are stored and updated.
    # Current implementation uses simple state vector 'b'.
    # --- End Potential Improvement Comment ---


    b = np.random.uniform(-1, 1, size=N_scen)
    A = np.abs(np.random.normal(loc=0.018, scale=0.006, size=(N_scen, N_scen)))
    np.fill_diagonal(A, 0.0)

    # Adding cluster structure
    num_clusters_scen = max(4, N_scen//150)
    cluster_assign_scen = np.random.randint(0, num_clusters_scen, size=N_scen)
    cluster_eq_scen = (cluster_assign_scen[:,None] == cluster_assign_scen[None,:]).astype(float)
    A += 0.028 * cluster_eq_scen
    A = np.maximum(A, 0.0)
    np.fill_diagonal(A, 0.0)

    malicious_idx = np.random.choice(np.arange(N_scen), size=max(1,int(N_scen*malicious_frac_scen)), replace=False)
    malicious_count = len(malicious_idx)


    # Initialize ctrl parameters for the scenario, potentially overridden
    ctrl = {
        'eta': current_params.get('init_eta', init_eta),
        'lambda': current_params.get('init_lambda', init_lambda),
        'gate_topk': current_params.get('init_gate_topk', init_gate_topk)
    }

    es_sigma = {'eta': 0.02, 'lambda': 0.006, 'gate_topk': 3.0} # ES sigmas can be fixed or part of params

    # Define parameter bounds inside the scenario loop as N_scen is available
    min_gate_topk, max_gate_topk = 1.0, float(N_scen)


    records = []
    scenario_start_time = time.time()
    # --- End Re-Initialization ---


    ---------- الحلقة الرئيسية ---------- # Keep the original main loop marker inside the loop
    for t in range(T_scen):
        A_gated = apply_gating(A, int(round(ctrl['gate_topk'])))

        # Calculate additional metrics for composite objective
        current_centrality = centrality_from_A(A_gated)
        avg_centrality = np.mean(current_centrality) # System-level centrality metric
        network_entropy_val = network_entropy(A_gated)
        robustness_val = compute_robustness(A_gated, malicious_idx, t)


        I = aggregate_inputs(A_gated, b)
        # هجوم خبيث دوري (اختياري)
        if t % 30 == 0 and t>0:
            mal_influence = (A_gated.T[:, malicious_idx].sum(axis=1) * 0.16)
            mean_b_malicious = np.mean(b[malicious_idx]) if malicious_idx.size > 0 else 0.0
            I = I + mal_influence * (mean_b_malicious * -0.36)


        b_new = update_states(b, I, alpha_scen, noise_sigma_scen)
        local_gain = np.tanh(np.abs(b_new - b))
        sim_mat = 1.0 - np.abs(b[:, None] - b[None, :])
        sim_mat = np.clip(sim_mat, 0.0, 1.0)
        reward_mat = sim_mat * local_gain[None, :]
        A_update = ctrl['eta'] * reward_mat - ctrl['lambda'] * A_gated
        if t % 30 == 0 and t>0:
            if malicious_idx.size > 0:
                A_update[malicious_idx, :] -= audit_strength_scen * np.abs(A_update[malicious_idx, :])

        A = A_gated + A_update
        A = np.maximum(A, 0.0)
        np.fill_diagonal(A, 0.0)
        energy = energy_of_A(A); S_val = compute_S(b_new)

        # --- Conceptual Insights: Future AI Dynamics / Risks/Benefits & Composite Objective (from تحليل الذكاء الاصطناعي .txt & Arabic files) ---
    # The original utility function weighted cohesion (S) and energy cost.
    # The new composite objective incorporates more factors (entropy, centrality, robustness)
    # informed by insights into desired system properties and risks.
    # --- End Conceptual Insights Comment --- # Comment for conceptual insights related to utility and composite
        # Calculate the original utility (for comparison)
                # --- Conceptual Insights: Future AI Dynamics / Risks/Benefits & Composite Objective (from تحليل الذكاء الاصطناعي .txt & Arabic files) ---
            # The original utility function weighted cohesion (S) and energy cost.
            # The new composite objective incorporates more factors (entropy, centrality, robustness)
            # informed by insights into desired system properties and risks.
            # --- End Conceptual Insights Comment ---
utility = w_S_scen * S_val - w_energy_scen * energy

        # Calculate the composite objective score for recording
        composite_score = compute_composite_objective(S_val, energy, network_entropy_val, avg_centrality, robustness_val, w_S_scen, w_energy_scen, N_scen)


        records.append({
            't': t,
            'S': S_val,
            'energy': energy,
            'utility': utility,
            'avg_A': A.mean(),
            'avg_centrality': avg_centrality, # Record average centrality
            'network_entropy': network_entropy_val, # Record network entropy
            'robustness': robustness_val, # Record robustness
            'composite_score': composite_score, # Record composite score
            'eta': ctrl['eta'],
            'lambda': ctrl['lambda'],
            'gate_topk': ctrl['gate_topk'],
            'malicious_count': malicious_count # Record malicious count (fixed per scenario run)
        })
        ---------- ES adaptive controller (تجربة قصيرة لعدة مرشحين) ---------- # Keep the original ES controller marker inside the loop
        if (t+1) % intervene_every_scen == 0 and t>0:
            cand_params=[]; cand_scores=[]
            print(f"  Intervention at time {t+1}. Running ES probe rollout. probe_steps_scen: {probe_steps_scen}")
            for k in range(es_population_scen):
                # --- Potential Improvement: Structured observation building process (from hard.txt) ---
        # Before the probe rollout, a formal 'observation' vector/dictionary could be built
        # summarizing the current state (metrics, ctrl params, state statistics) for the ES
        # candidates to use.
        # Current ES implicitly uses recent utility (probe_score) to guide adaptation.
        # --- End Potential Improvement Comment --- # Comment for structured observation
                # Generate candidate parameters
                cand={'eta': max(0.0, ctrl['eta'] + np.random.normal(0, es_sigma['eta'])),
                      'lambda': max(1e-6, ctrl['lambda'] + np.random.normal(0, es_sigma['lambda'])),
                      'gate_topk': max(1.0, ctrl['gate_topk'] + np.random.normal(0, es_sigma['gate_topk']))}

                # --- Apply Parameter Bounds to Candidate Parameters ---
                cand['eta'] = max(min_eta, min(max_eta, cand['eta']))
                cand['lambda'] = max(min_lambda, min(max_lambda, cand['lambda']))
                # min_gate_topk and max_gate_topk need N_scen, already defined at re-init
                cand['gate_topk'] = max(min_gate_topk, min(max_gate_topk, cand['gate_topk']))
                # --- End Apply Parameter Bounds ---

                # probe rollout (قصير)
                A_probe = A.copy(); b_probe = b_new.copy(); probe_composite_score = 0.0 # Use composite score for probe
                for p in range(probe_steps_scen):
                    A_p_g = apply_gating(A_probe, int(round(cand['gate_topk'])))

                    # Calculate metrics for composite score during probe
                    current_centrality_p = centrality_from_A(A_p_g)
                    avg_centrality_p = np.mean(current_centrality_p)
                    network_entropy_val_p = network_entropy(A_p_g)
                    robustness_val_p = compute_robustness(A_p_g, malicious_idx, t + p)


                    I_p = aggregate_inputs(A_p_g, b_probe)
                    if (t + p) % 30 == 0:
                        mal_influence_p = (A_p_g.T[:, malicious_idx].sum(axis=1) * 0.16)
                        mean_b_malicious_p = np.mean(b_probe[malicious_idx]) if malicious_idx.size > 0 else 0.0
                        I_p = I_p + mal_influence_p * (mean_b_malicious_p * -0.36)

                    b_pnew = update_states(b_probe, I_p, alpha_scen, noise_sigma_scen)
                    local_gain_p = np.tanh(np.abs(b_pnew - b_probe))
                    sim_mat_p = 1.0 - np.abs(b_probe[:, None] - b_probe[None, :])
                    sim_mat_p = np.clip(sim_mat_p, 0.0, 1.0)
                    reward_mat_p = sim_mat_p * local_gain_p[None, :]
                    A_update_p = cand['eta'] * reward_mat_p - cand['lambda'] * A_p_g
                    if (t + p) % 30 == 0:
                        if malicious_idx.size > 0:
                            A_update_p[malicious_idx, :] -= audit_strength_scen * np.abs(A_update_p[malicious_idx, :])
                    A_probe = np.maximum(A_p_g + A_update_p, 0.0); np.fill_diagonal(A_probe, 0.0)
                    energy_p = energy_of_A(A_probe); S_p = compute_S(b_pnew)

                    # Use composite objective for probe score accumulation
                    current_probe_step_composite_score = compute_composite_objective(S_p, energy_p, network_entropy_val_p, avg_centrality_p, robustness_val_p, w_S_scen, w_energy_scen, N_scen)

                    if np.isfinite(current_probe_step_composite_score):
                         probe_composite_score += current_probe_step_composite_score
                    # else:
                         # print(f"    Warning: Invalid probe score at time {t+p}. Skipping.")

                    b_probe = b_pnew

                # --- Handle Failed Probes Gracefully (Robust Probe Evaluation) ---
                # Check if the final probe_composite_score for this candidate is finite after the probe steps
                if np.isfinite(probe_composite_score):
                    cand_scores.append(probe_composite_score)
                    cand_params.append(cand) # Also append the candidate parameters
                else:
                    # Assign a fixed negative score if the probe failed (NaN/Inf)
                    # Append the fixed negative score and the candidate parameters
                    cand_scores.append(fixed_negative_probe_score)
                    cand_params.append(cand)
                    # print(f"  Warning: Final probe score for candidate {k+1} is invalid ({probe_composite_score}). Assigning fixed negative score.")
                # --- End Handle Failed Probes ---


            if cand_scores:
                best_idx = int(np.argmax(cand_scores)); best_cand = cand_params[best_idx]


                # --- Adaptive Move Fraction ---
                # Define the parameters for the adaptive move fraction mapping
                # These are example values, could be tuned
                variance_scaling = 10.0 # How much variance affects move_frac
                min_move_frac_adapt = 0.1 # Min move_frac
                max_move_frac_adapt = 0.8 # Max move_frac

                # Calculate variance of candidate scores (only if more than one score)
                scores_variance = 0.0
                if len(cand_scores) > 1:
                    scores_variance = np.var(cand_scores)

                # Map variance to a dynamic move_frac (using a simple linear mapping capped by bounds)
                dynamic_move_frac = min_move_frac_adapt + (max_move_frac_adapt - min_move_frac_adapt) * np.tanh(scores_variance * variance_scaling)

                # Ensure move_frac is within defined bounds
                move_frac = max(min_move_frac_adapt, min(max_move_frac_adapt, dynamic_move_frac))

                # Optional: Print the calculated variance and move_frac
                # print(f"  Probe scores variance: {scores_variance:.6f}}, Dynamic move_frac: {move_frac:.4f}}")
                # --- End Adaptive Move Fraction ---


                # Apply the move fraction to update ctrl parameters
                ctrl['eta'] = ctrl['eta']*(1-move_frac) + best_cand['eta']*move_frac
                ctrl['lambda'] = ctrl['lambda']*(1-move_frac) + best_cand['lambda']*move_frac
                ctrl['gate_topk'] = ctrl['gate_topk']*(1-move_frac) + best_cand['gate_topk']*move_frac

                # --- Apply Parameter Bounds to Ctrl Parameters (Hard Constraints) ---
                ctrl['eta'] = max(min_eta, min(max_eta, ctrl['eta']))
                ctrl['lambda'] = max(min_lambda, min(max_lambda, ctrl['lambda']))
                ctrl['gate_topk'] = max(min_gate_topk, min(max_gate_topk, ctrl['gate_topk']))
                # --- End Apply Parameter Bounds ---

                print(f"  Updated ctrl params: {ctrl}")

            else:
                print(f"  Warning: cand_scores is empty at time {t+1}. Skipping parameter update.")

        b = b_new.copy()
    # --- End Main Loop ---


    # ---------- حفظ النتائج ورسمها ---------- # Keep the original Saving/Plotting marker for clarity
    df = pd.DataFrame(records)
    scenario_results[scenario['name']] = df # Store DataFrame for comparison later

    # Optional: Save scenario-specific CSV
    fname = f"attention_es_large_results_{scenario['name'].replace(' ', '_').lower()}.csv"
    df.to_csv(fname, index=False)
    print(f"Saved metrics for scenario '{scenario['name']}' to {fname}")

    # Optional: Plot for current scenario (commented out as per previous attempts)
    # plt.figure(figsize=(10,3)); plt.plot(df['t'], df['S']); plt.title(f"Scenario: {scenario['name']} - S (cohesion)"); plt.show()
    # plt.figure(figsize=(10,3)); plt.plot(df['t'], df['utility']); plt.title(f"Scenario: {scenario['name']} - Utility"); plt.show()
    # if 'composite_score' in df.columns: # Check if composite_score was recorded
    #      plt.figure(figsize=(10,3)); plt.plot(df['t'], df['composite_score']); plt.title(f"Scenario: {scenario['name']} - Composite Score"); plt.show()


# --- End Scenario Experimentation Loop --- # This marker should be after the scenario loop


# --- Plotting Comparison Across Scenarios ---
print("\n--- Plotting Comparison Across Scenarios ---")

# Plot S comparison
plt.figure(figsize=(12, 6))
for name, df_res in scenario_results.items():
    plt.plot(df_res['t'], df_res['S'], label=name)
plt.title('S (Cohesion) Comparison Across Scenarios')
plt.xlabel('Time Step')
plt.ylabel('S')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Plot Utility comparison
plt.figure(figsize=(12, 6))
for name, df_res in scenario_results.items():
    plt.plot(df_res['t'], df_res['utility'], label=name)
plt.title('Utility Comparison Across Scenarios')
plt.xlabel('Time Step')
plt.ylabel('Utility')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Plot Composite Score comparison (if calculated)
# Check if 'composite_score' column exists in at least one result DataFrame
if any('composite_score' in df_res.columns for df_res in scenario_results.values()):
    plt.figure(figsize=(12, 6))
    for name, df_res in scenario_results.items():
        if 'composite_score' in df_res.columns: # Only plot if the column exists for this scenario
            plt.plot(df_res['t'], df_res['composite_score'], label=name)
    plt.title('Composite Score Comparison Across Scenarios')
    plt.xlabel('Time Step')
    plt.ylabel('Composite Score')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Plot Control Parameters comparison (e.g., eta, lambda) for the first scenario
# Assuming ES adapts params within each scenario run and we want to see one example trajectory.
if scenario_results: # Check if scenario_results is not empty
    first_scenario_name = next(iter(scenario_results.keys()))
    df_first_scenario = scenario_results[first_scenario_name]
    plt.figure(figsize=(12, 6))
    plt.plot(df_first_scenario['t'], df_first_scenario['eta'], label=f"{first_scenario_name} - eta")
    plt.plot(df_first_scenario['t'], df_first_scenario['lambda'], label=f"{first_scenario_name} - lambda")
    plt.plot(df_first_scenario['t'], df_first_scenario['gate_topk'], label=f"{first_scenario_name} - gate_topk") # Also plot gate_topk
    plt.title(f'Control Parameters over Time ({first_scenario_name} Scenario)')
    plt.xlabel('Time Step')
    plt.ylabel('Parameter Value')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()
else:
    print("No scenario results available to plot control parameters.")

# --- End Plotting Comparison Across Scenarios --- # Added a new end marker for clarity

