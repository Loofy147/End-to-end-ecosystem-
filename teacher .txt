from dataclasses import dataclass, asdict, field
from typing import Dict, List, Any, Optional, Tuple
import json
import torch
import numpy as np
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM
from sentence_transformers import SentenceTransformer
from tqdm.auto import tqdm
import pdfplumber
import docx
from pptx import Presentation
import re
import pandas as pd
from collections import defaultdict
import os # Import os for file discovery

# Redefine device to ensure it's accessible
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ”§ Ø§Ù„Ø¬Ù‡Ø§Ø²: {device}")


@dataclass
class KnowledgeNode:
    id: str
    type: str  # 'concept', 'file', 'chunk', 'objective'
    name: str
    attributes: Dict[str, Any] = field(default_factory=dict)

@dataclass
class KnowledgeRelationship:
    source_id: str
    target_id: str
    type: str # 'explains', 'part_of', 'prerequisite_for', 'covers', 'related_to', 'is_an_example_of', 'contrasts_with', 'requires_knowledge_from'
    attributes: Dict[str, Any] = field(default_factory=dict)


class KnowledgeGraph:
    """Simple in-memory Knowledge Graph using dictionaries."""
    def __init__(self):
        self.nodes: Dict[str, KnowledgeNode] = {}
        self.relationships: List[KnowledgeRelationship] = []
        self._node_counter = 0

    def add_node(self, node: KnowledgeNode):
        if node.id not in self.nodes:
            self.nodes[node.id] = node

    def add_relationship(self, relationship: KnowledgeRelationship):
        # Simple check to avoid duplicate relationships of the same type between the same nodes
        is_duplicate = any(
            r.source_id == relationship.source_id and
            r.target_id == relationship.target_id and
            r.type == relationship.type
            for r in self.relationships
        )
        if relationship.source_id in self.nodes and relationship.target_id in self.nodes and not is_duplicate:
            self.relationships.append(relationship)
        else:
            pass # Optionally log warning for missing nodes or duplicates

    def get_node(self, node_id: str) -> Optional[KnowledgeNode]:
        return self.nodes.get(node_id)

    def get_relationships(self, node_id: str = None, rel_type: str = None) -> List[KnowledgeRelationship]:
        filtered_rels = []
        for rel in self.relationships:
            if (node_id is None or rel.source_id == node_id or rel.target_id == node_id) and \
               (rel_type is None or rel.type == rel_type):
                filtered_rels.append(rel)
        return filtered_rels

    def query(self, start_node_id: str = None, relationship_type: str = None, target_node_type: str = None) -> List[Dict]:
        results = []
        for rel in self.relationships:
            if (start_node_id is None or rel.source_id == start_node_id) and \
               (relationship_type is None or rel.type == relationship_type):
                target_node = self.get_node(rel.target_id)
                if target_node and (target_node_type is None or target_node.type == target_node_type):
                     results.append({
                         'source': self.get_node(rel.source_id),
                         'relationship': rel,
                         'target': target_node
                     })
        return results

    def _generate_node_id(self, node_type: str, name: str) -> str:
        self._node_counter += 1
        return f"{node_type}_{self._node_counter}_{abs(hash(name))}"


class IntelligentTeacher:
    """Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø°ÙŠ ÙŠØ³ØªØ®Ø¯Ù… Ù…Ù„ÙØ§ØªÙƒ Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Knowledge Graph Ùˆ Meta-Learning"""

    def __init__(self, teacher_model: str = "microsoft/DialoGPT-large"):

        print(f"ğŸ§  ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ: {teacher_model}")

        # Check if model weights exist locally, otherwise download (simplified)
        # This check is still needed to avoid re-downloading large models if they persist
        try:
            # Try loading tokenizer first (smaller)
            self.tokenizer = AutoTokenizer.from_pretrained(teacher_model)
            # Then try loading model (larger) - this might fail if not cached
            self.model = AutoModelForCausalLM.from_pretrained(
                teacher_model,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
            ).to(device) # Use the global device

            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token

            print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­.")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {teacher_model}: {e}")
            print("âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©.")
            # Define dummy tokenizer and model if loading fails
            class DummyTokenizer:
                def __call__(self, prompt, return_tensors, padding, truncation, max_length):
                    print(f"DummyTokenizer called with prompt: {prompt[:50]}...")
                    # Return dummy tensor structure
                    return {'input_ids': torch.randint(0, 1000, (1, min(len(prompt), max_length))), 'attention_mask': torch.ones(1, min(len(prompt), max_length))}
                @property
                def eos_token_id(self):
                    return 50000 # Dummy EOS token id
                @property
                def pad_token(self):
                    return None # Dummy pad token

            class DummyModel:
                def generate(self, input_ids, attention_mask, max_new_tokens, num_return_sequences, pad_token_id, no_repeat_ngram_size, early_stopping, temperature, top_p):
                    print("DummyModel generate called.")
                    # Return a dummy output tensor
                    dummy_output = torch.randint(0, 1000, (num_return_sequences, input_ids.shape[1] + max_new_tokens))
                    return dummy_output

            self.tokenizer = DummyTokenizer()
            self.model = DummyModel()
            self.device = 'cpu' # Ensure device is cpu for dummy model


        self.teaching_memory = {
            'concepts_taught': set(),
            'student_profiles': {},
            'strategy_performance_logs': [], # List of dicts: {'student_id': str, 'content_id': str, 'strategy_used': str, 'outcome': str, 'time_taken': float}
            'curriculum_effectiveness_feedback': {},
            'learning_progress': {}
        }

        self.teaching_strategies = self._init_strategies()

        self.knowledge_graph = KnowledgeGraph()

        self.meta_learning_insights = {
            'strategy_effectiveness_patterns': {}, # e.g., 'conceptual' works well for 'technical' content for 'beginner' students
            'common_prerequisite_issues': {}, # e.g., students struggle with concept X if they didn't master concept Y
            'optimal_sequencing_patterns': {} # e.g., curriculum path A leads to better retention than path B
        }

    def _init_strategies(self):
        return {
            'conceptual': {
                'name': 'Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ÙŠ',
                'approach': 'ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹',
                'prompt_template': """
                Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø®Ø¨ÙŠØ±. Ø§Ø´Ø±Ø­ Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ØªØ¯Ø±Ø¬Ø©:

                Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ù…Ù„Ù: {content}
                Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {concept}

                Ù‚Ø¯Ù…:
                1. ØªØ¹Ø±ÙŠÙ ÙˆØ§Ø¶Ø­
                2. Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                3. ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…Ø®ØªÙ„ÙØ©
                4. Ø£Ø³Ø¦Ù„Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙÙ‡Ù…

                Ø§Ù„Ø´Ø±Ø­:
                """
            },
            'practical': {
                'name': 'Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ÙŠ',
                'approach': 'Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ',
                'prompt_template': """
                Ø£Ù†Øª Ù…Ø¹Ù„Ù… ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ. Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:

                Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {content}
                Ø§Ù„Ù‡Ø¯Ù: {objective}

                ØµÙ…Ù… ØªÙ…Ø±ÙŠÙ†Ø§Ù‹ Ø¹Ù…Ù„ÙŠØ§Ù‹ ÙŠØªØ¶Ù…Ù†:
                1. Ù…Ø´ÙƒÙ„Ø© ÙˆØ§Ù‚Ø¹ÙŠØ©
                2. Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø­Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                3. Ø£Ù…Ø«Ù„Ø© Ù…ØªØ¯Ø±Ø¬Ø© Ø§Ù„ØµØ¹ÙˆØ¨Ø©
                4. Ù…Ø¹Ø§ÙŠÙŠØ± ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ø¬Ø§Ø­

                Ø§Ù„ØªÙ…Ø±ÙŠÙ†:
                """
            },
            'adaptive': {
                'name': 'Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„ØªÙƒÙŠÙÙŠ',
                'approach': 'Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ ÙˆÙ†Ù…Ø· Ø§Ù„ØªØ¹Ù„Ù…',
                'prompt_template': """
                Ø£Ù†Øª Ù…Ø¹Ù„Ù… ØªÙƒÙŠÙÙŠ Ø°ÙƒÙŠ. Ø­Ù„Ù„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆÙ‚Ø¯Ù… Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨:

                Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {content}
                Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ø³Ø§Ø¨Ù‚: {performance_history}
                Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù: {weaknesses}

                Ù‚Ø¯Ù… ØªØ¹Ù„ÙŠÙ…Ø§Ù‹ Ù…Ø®ØµØµØ§Ù‹ ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰:
                1. ØªÙ‚ÙˆÙŠØ© Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù
                2. Ø§Ù„Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©
                3. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…ÙØ¶Ù„
                4. ØªØ¯Ø±Ø¬ Ù…Ù†Ø§Ø³Ø¨ ÙÙŠ Ø§Ù„ØµØ¹ÙˆØ¨Ø©

                Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…Ø®ØµØµ:
                """
            }
        }

    # Modify populate_knowledge_graph to add more granular relationships
    def populate_knowledge_graph(self, knowledge_units: Dict[str, Dict]):
        print("Building knowledge graph...")
        file_nodes = {}
        concept_nodes_map = {} # Map concept name to node ID for easier lookup
        content_analysis_results = {} # To store deep analysis results needed for relationships


        # First, perform deep content analysis to get potential relationships
        print("Performing deep content analysis for relationship extraction...")
        for filename, unit in knowledge_units.items():
             # Use actual LLM call here if model is loaded, or keep simulation
             content_analysis_results[filename] = self._deep_content_analysis(unit)
             print(f"  ğŸ” ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù„Ù€: {filename} Ù…ÙƒØªÙ…Ù„.")

        # Now, populate the graph using knowledge units and deep analysis results
        print("Populating graph nodes and basic relationships...")
        for filename, unit in knowledge_units.items():
            file_node_id = self.knowledge_graph._generate_node_id('file', filename)
            file_node = KnowledgeNode(id=file_node_id, type='file', name=filename, attributes={'difficulty': unit.get('difficulty_level', 0), 'content_type': unit.get('content_type', 'general'), 'total_length': unit.get('total_length', 0)})
            self.knowledge_graph.add_node(file_node)
            file_nodes[filename] = file_node_id

            # Add Chunk nodes and relationships to File
            chunk_nodes = []
            for chunk in unit.get('chunks', []):
                chunk_node_id = self.knowledge_graph._generate_node_id('chunk', f"{filename}_chunk_{chunk.get('chunk_id', 0)}")
                chunk_node = KnowledgeNode(id=chunk_node_id, type='chunk', name=f"Chunk {chunk.get('chunk_id', 0)} from {filename}", attributes={'text_preview': chunk.get('text', '')[:100] + '...'})
                self.knowledge_graph.add_node(chunk_node)
                self.knowledge_graph.add_relationship(KnowledgeRelationship(source_id=chunk_node_id, target_id=file_node_id, type='part_of'))
                chunk_nodes.append(chunk_node) # Keep track of chunk nodes for this file

            # Add Concept nodes and relationships to File and Chunks
            for concept in unit.get('concepts', []):
                concept_node_id = concept_nodes_map.get(concept)
                if concept_node_id is None:
                    concept_node_id = self.knowledge_graph._generate_node_id('concept', concept)
                    concept_node = KnowledgeNode(id=concept_node_id, type='concept', name=concept)
                    self.knowledge_graph.add_node(concept_node)
                    concept_nodes_map[concept] = concept_node_id

                # Relate concept to the file
                self.knowledge_graph.add_relationship(KnowledgeRelationship(source_id=file_node_id, target_id=concept_node_id, type='covers'))

                # Relate concept to relevant chunks (simplified: relate to all chunks in the file for now)
                for chunk_node in chunk_nodes:
                     self.knowledge_graph.add_relationship(KnowledgeRelationship(source_id=chunk_node.id, target_id=concept_node_id, type='explains'))

        print("Adding advanced relationships based on analysis...")
        # --- Advanced Relationships based on Deep Analysis ---
        # We need to iterate through all nodes (especially concepts and files)
        # and the content_analysis_results to add relationships.

        # Create reverse maps for easier lookup
        file_name_to_id = {node.name: node.id for node in self.knowledge_graph.nodes.values() if node.type == 'file'}
        concept_name_to_id = {node.name: node.id for node in self.knowledge_graph.nodes.values() if node.type == 'concept'}


        for filename, analysis in content_analysis_results.items():
             file_node_id = file_name_to_id.get(filename) # Use the reverse map
             if not file_node_id:
                  print(f"  âš ï¸ File node not found for filename: {filename}")
                  continue

             # 1. Prerequisite Relationships
             prereqs = analysis.get('prerequisites', [])
             for prereq_text in prereqs:
                 # Try to find nodes whose name matches or is similar to the prerequisite text.
                 found_prereq_node_id = None

                 # Check if it's a file name
                 prereq_file_node_id = file_name_to_id.get(prereq_text)
                 if prereq_file_node_id:
                      found_prereq_node_id = prereq_file_node_id
                 else:
                      # Check if it's a concept name (simple exact match for now)
                      prereq_concept_node_id = concept_name_to_id.get(prereq_text)
                      if prereq_concept_node_id:
                           found_prereq_node_id = prereq_concept_node_id

                 if found_prereq_node_id and found_prereq_node_id != file_node_id: # Avoid self-loops
                      self.knowledge_graph.add_relationship(KnowledgeRelationship(source_id=file_node_id, target_id=found_prereq_node_id, type='requires_knowledge_from'))
                      # print(f"  ğŸ”— Added prerequisite relationship: {filename} --(requires_knowledge_from)--> {prereq_text}") # Keep print optional
                 elif not found_prereq_node_id:
                      pass # print(f"  âš ï¸ Could not link prerequisite '{prereq_text}' from {filename} to an existing graph node.") # Keep print optional


             # 2. Related To relationships based on Connections
             connections = analysis.get('connections', [])
             for connection_text in connections:
                  # Similar to prerequisites, try to link connection_text to existing nodes
                  found_connection_node_id = None
                  # Check files first
                  connected_file_node_id = file_name_to_id.get(connection_text)
                  if connected_file_node_id:
                       found_connection_node_id = connected_file_node_id
                  else:
                       # Check concepts (simple exact match)
                       connected_concept_node_id = concept_name_to_id.get(connection_text)
                       if connected_concept_node_id:
                            found_connection_node_id = connected_concept_node_id


                  if found_connection_node_id and found_connection_node_id != file_node_id: # Avoid self-loops
                       self.knowledge_graph.add_relationship(KnowledgeRelationship(source_id=file_node_id, target_id=found_connection_node_id, type='related_to'))
                       # print(f"  ğŸ”— Added related_to relationship: {filename} --(related_to)--> {connection_text}") # Keep print optional
                  elif not found_connection_node_id:
                       pass # print(f"  âš ï¸ Could not link connection '{connection_text}' from {filename} to an existing graph node.") # Keep print optional


             # 3. Example/Contrast Relationships (Simulated or Rule-Based)
             # This is complex and would typically require LLM analysis of text or pattern matching within chunks.
             # For demonstration, let's add 'is_an_example_of' relationships between the first chunk and the first concept in each file,
             # but only if both exist and the concept node was successfully created.
             current_file_chunks = [node for node in self.knowledge_graph.nodes.values() if node.type == 'chunk' and node.attributes.get('text_preview', '').startswith(f"Chunk 0 from {filename}")]
             if current_file_chunks and unit.get('concepts'):
                 example_chunk_node = current_file_chunks[0] # Pick the first chunk node created for this file
                 first_concept = unit['concepts'][0] # Pick the first concept from the unit data
                 first_concept_node_id = concept_name_to_id.get(first_concept) # Get the ID using the map

                 if first_concept_node_id:
                      self.knowledge_graph.add_relationship(KnowledgeRelationship(source_id=example_chunk_node.id, target_id=first_concept_node_id, type='is_an_example_of'))
                      # print(f"  ğŸ”— Added simulated relationship: {example_chunk_node.name} --(is_an_example_of)--> {first_concept}") # Keep print optional


        print(f"Knowledge graph built with {len(self.knowledge_graph.nodes)} nodes and {len(self.knowledge_graph.relationships)} relationships.")


    def analyze_knowledge_corpus(self, knowledge_units: Dict[str, Dict]) -> Dict:
        print("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Knowledge Graph...")
        # The deep analysis and graph population are now integrated into populate_knowledge_graph
        # We will call populate_knowledge_graph first.
        self.populate_knowledge_graph(knowledge_units)


        analysis = {
            'content_map': {}, # Deep analysis results are generated within populate_knowledge_graph now
            'difficulty_distribution': {},
            'concept_hierarchy': {},
            'learning_path': [],
            'training_priorities': []
        }

        # Retrieve difficulty levels from file nodes in the populated graph
        difficulty_levels = [node.attributes.get('difficulty', 0) for node in self.knowledge_graph.nodes.values() if node.type == 'file']
        analysis['difficulty_distribution'] = {
            'beginner': len([d for d in difficulty_levels if d < 0.3]),
            'intermediate': len([d for d in difficulty_levels if 0.3 <= d < 0.7]),
            'advanced': len([d for d in difficulty_levels if d >= 0.7])
        }

        # Analyze concept coverage and hierarchy from the populated graph
        concept_coverage = {}
        for concept_node in [node for node in self.knowledge_graph.nodes.values() if node.type == 'concept']:
            # Query for relationships where this concept is the target and source is a file
            covering_files_rels = self.knowledge_graph.query(start_node_id=None, relationship_type='covers', target_node_type='concept')
            files_covering_this_concept = [res['source'] for res in covering_files_rels if res['target'] and res['target'].id == concept_node.id and res['source'].type == 'file']
            concept_coverage[concept_node.name] = len(files_covering_this_concept)

        sorted_concepts = sorted(concept_coverage.items(), key=lambda x: x[1], reverse=True)
        analysis['concept_hierarchy'] = {
            'core_concepts': [c[0] for c in sorted_concepts[:min(10, len(sorted_concepts))]],
            'secondary_concepts': [c[0] for c in sorted_concepts[min(10, len(sorted_concepts)):min(20, len(sorted_concepts))]],
            'advanced_concepts': [c[0] for c in sorted_concepts[min(20, len(sorted_concepts)):]]
        }

        # Generate learning path considering the new 'requires_knowledge_from' relationships
        # This still uses a simple difficulty sort for demonstration, but prerequisites are from the graph
        sorted_file_nodes = sorted(
            [node for node in self.knowledge_graph.nodes.values() if node.type == 'file'],
            key=lambda x: x.attributes.get('difficulty', 0)
        )

        learning_path = []
        for i, file_node in enumerate(sorted_file_nodes):
            filename = file_node.name
            unit_info = knowledge_units.get(filename, {})

            # Get concepts covered by this file from the graph
            concepts_covered_by_this_file_rels = self.knowledge_graph.query(start_node_id=file_node.id, relationship_type='covers', target_node_type='concept')
            key_concepts = [self.knowledge_graph.get_node(res['target'].id).name for res in concepts_covered_by_this_file_rels if res['target']][:5]

            # Get prerequisites from the graph using the 'requires_knowledge_from' relationship type
            prereqs_from_graph_rels = self.knowledge_graph.query(start_node_id=file_node.id, relationship_type='requires_knowledge_from', target_node_type=None) # Target can be file or concept
            prereqs = [f"Requires knowledge from {self.knowledge_graph.get_node(res['target'].id).name}" for res in prereqs_from_graph_rels if res['target']]

            # Note: _deep_content_analysis is called within populate_knowledge_graph now,
            # its results are used to add relationships directly there.
            # We don't need to re-extract prerequisites here, they are already in the graph.

            step = {
                'step_number': i + 1,
                'filename': filename,
                'content_type': file_node.attributes.get('content_type', 'general'),
                'difficulty': file_node.attributes.get('difficulty', 0),
                'key_concepts': key_concepts,
                'estimated_time': self._estimate_learning_time(unit_info),
                'prerequisites': prereqs,
                'learning_objectives': self._generate_step_objectives(unit_info)
            }
            learning_path.append(step)

        analysis['learning_path'] = learning_path

        analysis['training_priorities'] = self._determine_training_priorities(analysis)

        # Add learning path steps and objectives to the graph (using updated path)
        for step in analysis['learning_path']:
            step_node_id = self.knowledge_graph._generate_node_id('learning_step', f"Step {step['step_number']} - {step['filename']}")
            step_node = KnowledgeNode(id=step_node_id, type='learning_step', name=f"Step {step['step_number']}", attributes=step)
            self.knowledge_graph.add_node(step_node)

            file_node_id = None
            for nid, node in self.knowledge_graph.nodes.items():
                if node.type == 'file' and node.name == step['filename']:
                    file_node_id = nid
                    break
            if file_node_id:
                self.knowledge_graph.add_relationship(KnowledgeRelationship(source_id=step_node_id, target_id=file_node_id, type='based_on_file'))

            for obj_text in step.get('learning_objectives', []):
                 obj_node_id = self.knowledge_graph._generate_node_id('objective', obj_text)
                 obj_node = KnowledgeNode(id=obj_node_id, type='objective', name=obj_text)
                 self.knowledge_graph.add_node(obj_node)
                 self.knowledge_graph.add_relationship(KnowledgeRelationship(source_id=step_node_id, target_id=obj_node_id, type='achieves_objective'))

        # Call the performance analysis method
        self._analyze_performance_logs()

        return analysis

    def create_training_curriculum(self,
                                   knowledge_analysis: Dict,
                                   target_competencies: List[str] = None) -> Dict:
        print("ğŸ“š Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù†Ù‡Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Knowledge Graph Ùˆ Meta-Learning...")
        curriculum = {
            'phases': [],
            'total_duration': 0,
            'competency_map': {},
            'assessment_strategy': {},
            'personalization_rules': {}
        }

        learning_path = knowledge_analysis.get('learning_path', [])
        concept_hierarchy = knowledge_analysis.get('concept_hierarchy', {})

        # Phase 1: Foundation
        foundation_phase_units = [
            step for step in learning_path
            if step['difficulty'] < 0.5
        ]
        # Meta-learning influence: Suggest initial strategy based on general patterns and meta-learning insights
        suggested_foundation_strategy = self._suggest_teaching_strategy(
            phase='foundation',
            student_profile='general_student_profile', # Placeholder
            key_concepts=concept_hierarchy.get('core_concepts', []),
            avg_difficulty=0.3,
            content_type='educational' # Assume foundational content is educational
        )
        foundation_phase = self._create_curriculum_phase(
            name='Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ§Øª ÙˆØ§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©',
            description='Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©.',
            content_units=foundation_phase_units,
            suggested_strategy=suggested_foundation_strategy,
            assessment_type='quizzes',
            key_concepts=concept_hierarchy.get('core_concepts', [])
        )
        curriculum['phases'].append(foundation_phase)

        # Phase 2: Application
        application_phase_units = [
            step for step in learning_path
            if 0.3 <= step['difficulty'] < 0.8
        ]
        suggested_application_strategy = self._suggest_teaching_strategy(
            phase='application',
            student_profile='general_student_profile', # Placeholder
            key_concepts=concept_hierarchy.get('secondary_concepts', []),
            avg_difficulty=0.6,
            content_type='technical' # Assume application content is often technical/practical
        )
        application_phase = self._create_curriculum_phase(
            name='Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ù„ØªÙ…Ø§Ø±ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ÙŠØ©',
            description='ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…ÙƒØªØ³Ø¨Ø© Ù…Ù† Ø®Ù„Ø§Ù„ ØªÙ…Ø§Ø±ÙŠÙ† Ø¹Ù…Ù„ÙŠØ© ÙˆØ­Ù„ Ù…Ø´Ø§ÙƒÙ„.',
            content_units=application_phase_units,
            suggested_strategy=suggested_application_strategy,
            assessment_type='exercises',
            key_concepts=concept_hierarchy.get('secondary_concepts', [])
        )
        curriculum['phases'].append(application_phase)


        # Phase 3: Advanced/Specialization
        advanced_phase_units = [
            step for step in learning_path
            if step['difficulty'] >= 0.6
        ]
        if target_competencies:
             target_concept_ids = {node.id for node in self.knowledge_graph.nodes.values() if node.type == 'concept' and node.name in target_competencies}
             relevant_file_ids = set()
             for concept_id in target_concept_ids:
                 files_covering_concept_rels = self.knowledge_graph.query(start_node_id=None, relationship_type='covers', target_node_type='concept')
                 relevant_file_ids.update({res['source'].id for res in files_covering_concept_rels if res['target'] and res['target'].id == concept_id and res['source'].type == 'file'})

             advanced_phase_units = [
                 step for step in advanced_phase_units
                 if any(self.knowledge_graph.get_node(node_id) and self.knowledge_graph.get_node(node_id).name == step['filename'] for node_id in relevant_file_ids)
             ]

        suggested_advanced_strategy = self._suggest_teaching_strategy(
            phase='advanced',
            student_profile='general_student_profile', # Placeholder
            key_concepts=concept_hierarchy.get('advanced_concepts', []),
            avg_difficulty=0.8,
            content_type='technical' # Assume advanced content is often technical
        )
        advanced_phase = self._create_curriculum_phase(
            name='Ø§Ù„ØªÙ‚Ø¯Ù… ÙˆØ§Ù„ØªØ®ØµØµ',
            description='Ø§Ù„ØªØ¹Ù…Ù‚ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆØ§Ù„ØªØ®ØµØµ ÙÙŠ Ù…Ø¬Ø§Ù„Ø§Øª Ù…Ø­Ø¯Ø¯Ø©.',
            content_units=advanced_phase_units,
            suggested_strategy=suggested_advanced_strategy,
            assessment_type='projects_and_discussions',
            key_concepts=concept_hierarchy.get('advanced_concepts', [])
        )
        curriculum['phases'].append(advanced_phase)

        curriculum['assessment_strategy'] = self._design_assessment_strategy(knowledge_analysis)
        curriculum['total_duration'] = sum(p.get('estimated_duration', 0) for p in curriculum['phases'])
        curriculum['competency_map'] = self._map_competencies_graph(target_competencies)
        curriculum['personalization_rules'] = self._define_personalization_rules_meta(knowledge_analysis)

        return curriculum

    def _create_curriculum_phase(self, name: str, description: str, content_units: List[Dict], suggested_strategy: str, assessment_type: str, key_concepts: List[str]) -> Dict:
        estimated_duration = sum(unit.get('estimated_time', 0) for unit in content_units)
        return {
            'name': name,
            'description': description,
            'content_units': content_units,
            'teaching_strategy': suggested_strategy,
            'assessment_type': assessment_type,
            'estimated_duration': estimated_duration,
            'key_concepts': key_concepts
        }

    def _design_assessment_strategy(self, knowledge_analysis: Dict) -> Dict:
        return {
            'overall_approach': 'ØªÙ‚ÙŠÙŠÙ… Ù…Ø³ØªÙ…Ø± Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ÙÙ‡Ù… ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©.',
            'methods_per_phase': {
                'Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ§Øª ÙˆØ§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©': 'Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù‚ØµÙŠØ±Ø© ÙˆØ£Ø³Ø¦Ù„Ø© ÙÙ‡Ù….',
                'Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ù„ØªÙ…Ø§Ø±ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ÙŠØ©': 'ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªÙ…Ø§Ø±ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ÙˆØ¬ÙˆØ¯Ø© Ø§Ù„Ø­Ù„ÙˆÙ„.',
                'Ø§Ù„ØªÙ‚Ø¯Ù… ÙˆØ§Ù„ØªØ®ØµØµ': 'ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ ÙˆØ§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø§Øª.'
            },
            'feedback_mechanism': 'ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ø§Ø­Ø¸Ø§Øª ØªÙØµÙŠÙ„ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØªÙˆØ¬ÙŠÙ‡Ø§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†.',
            'remediation_strategy': 'ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù ÙˆØªÙ‚Ø¯ÙŠÙ… Ù…ÙˆØ§Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ© Ø£Ùˆ ØªÙ…Ø§Ø±ÙŠÙ† Ù…ÙˆØ¬Ù‡Ø©.'
        }

    def _map_competencies_graph(self, target_competencies: List[str] = None) -> Dict:
        competency_map = {}
        if target_competencies:
            for comp in target_competencies:
                related_concepts = []
                for concept_node in [node for node in self.knowledge_graph.nodes.values() if node.type == 'concept']:
                    if comp.lower() in concept_node.name.lower() or concept_node.name.lower() in comp.lower():
                        related_concepts.append(concept_node.name)
                competency_map[comp] = related_concepts
        return competency_map

    # Modify _define_personalization_rules_meta to use meta_learning_insights
    def _define_personalization_rules_meta(self, knowledge_analysis: Dict) -> Dict:
        """ØªØ­Ø¯ÙŠØ¯ Ù‚ÙˆØ§Ø¹Ø¯ ØªØ®ØµÙŠØµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Meta-Learning)"""
        rules = {
            'difficulty_adjustment': 'ØªØ¹Ø¯ÙŠÙ„ ØµØ¹ÙˆØ¨Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ù„ØªÙ…Ø§Ø±ÙŠÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø·Ø§Ù„Ø¨.',
            'strategy_selection': 'Ø§Ø®ØªÙŠØ§Ø± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø£Ù†Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙØ¶ÙŠÙ„Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆØ£Ø¯Ø§Ø¦Ù‡ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙˆØ£Ù†Ù…Ø§Ø· ÙØ¹Ø§Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Meta-Learning.',
            'content_recommendation': 'Ø§Ù‚ØªØ±Ø§Ø­ Ù…Ø­ØªÙˆÙ‰ Ø¥Ø¶Ø§ÙÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆÙ†Ù‚Ø§Ø· Ù‚ÙˆØªÙ‡/Ø¶Ø¹ÙÙ‡ (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Knowledge Graph Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·) ÙˆØ§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù…Ù† Meta-Learning.',
            'pace_control': 'Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ø·Ø§Ù„Ø¨ Ø¨Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ ÙˆØªÙŠØ±Ø© Ø§Ù„ØªØ¹Ù„Ù….',
            'feedback_style': 'ØªØ®ØµÙŠØµ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù„ÙŠÙ†Ø§Ø³Ø¨ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ù„ÙÙ‡ Ø§Ù„Ø´Ø®ØµÙŠ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©.'
        }

        # Add meta-learning based adjustments (illustrative)
        if self.meta_learning_insights.get('strategy_effectiveness_patterns'):
            rules['strategy_selection'] += " (Ù…ÙØ¹Ø¯Ù‘Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· ÙØ¹Ø§Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©: " + json.dumps(self.meta_learning_insights['strategy_effectiveness_patterns'], ensure_ascii=False) + ")"

        if self.meta_learning_insights.get('common_prerequisite_issues'):
             # Identify content/concepts from common prerequisite issues
             struggling_items = list(self.meta_learning_insights['common_prerequisite_issues'].keys())
             if struggling_items:
                rules['prerequisite_reinforcement'] = f"ØªÙ‚Ø¯ÙŠÙ… Ù…ÙˆØ§Ø¯ Ø£Ùˆ ØªÙ…Ø§Ø±ÙŠÙ† Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ù…ÙØ§Ù‡ÙŠÙ…/Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªÙŠ ØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡Ø§ Ø¹Ù„Ù‰ Ø£Ù†Ù‡Ø§ ØªØ³Ø¨Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ù…ØªÙƒØ±Ø±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Meta-Learning ({', '.join(struggling_items)})."
             else:
                 rules['prerequisite_reinforcement'] = 'ØªÙ‚Ø¯ÙŠÙ… Ù…ÙˆØ§Ø¯ Ø£Ùˆ ØªÙ…Ø§Ø±ÙŠÙ† Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡Ø§ Ø¹Ù„Ù‰ Ø£Ù†Ù‡Ø§ ØªØ³Ø¨Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ù…ØªÙƒØ±Ø±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Meta-Learning.'


        if self.meta_learning_insights.get('optimal_sequencing_patterns'):
             rules['sequencing_adjustment'] = "ØªØ¹Ø¯ÙŠÙ„ ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ø«Ù„Ù‰ Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Meta-Learning."
        else:
             rules['sequencing_adjustment'] = "ØªØ¹Ø¯ÙŠÙ„ ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ø«Ù„Ù‰ Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Meta-Learning." # Default description

        return rules

    # Modify _suggest_teaching_strategy to use meta_learning_insights
    def _suggest_teaching_strategy(self, phase: str, student_profile: str, key_concepts: List[str], avg_difficulty: float, content_type: str = 'general') -> str:
        """Suggest a teaching strategy based on phase, student, content, and meta-learning insights."""
        # print(f"\nğŸ§ Ø§Ù‚ØªØ±Ø§Ø­ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„Ù€: Ø§Ù„Ù…Ø±Ø­Ù„Ø© '{phase}', Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ '{content_type}', Ø§Ù„ØµØ¹ÙˆØ¨Ø© {avg_difficulty:.2f}, Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…: {key_concepts[:3]}...") # Keep print optional

        # Check meta-learning insights for patterns related to this content type/difficulty
        effectiveness_patterns = self.meta_learning_insights.get('strategy_effectiveness_patterns', {})
        # print(f"  Ø£Ù†Ù…Ø§Ø· ÙØ¹Ø§Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©: {effectiveness_patterns}") # Keep print optional

        # Simple logic: if meta-learning suggests a strategy is particularly effective for this content type, favor it.
        # This is a simplified simulation; a real system would need more granular pattern matching.
        suggested_strategy = None
        best_strategy_from_meta = None
        best_success_rate = -1

        # Find the strategy with the highest success rate in meta-learning insights
        for strategy, outcome_str in effectiveness_patterns.items():
            match = re.search(r"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: (\d+\.\d+)", outcome_str)
            if match:
                success_rate = float(match.group(1))
                # Prioritize strategies with higher success rates
                if success_rate > best_success_rate:
                    best_success_rate = success_rate
                    best_strategy_from_meta = strategy
                # If success rates are equal, prioritize certain strategies (e.g., conceptual for foundation) - simplified
                elif success_rate == best_success_rate:
                     if phase == 'foundation' and strategy == 'conceptual':
                         best_strategy_from_meta = 'conceptual'
                     elif phase == 'application' and strategy == 'practical':
                         best_strategy_from_meta = 'practical'
                     elif phase == 'advanced' and strategy == 'adaptive':
                         best_strategy_from_meta = 'adaptive'


        if best_strategy_from_meta and best_success_rate > 0.7: # Only use meta-learning suggestion if success rate is reasonably high (threshold 0.7)
             # Further refine based on content type - simple mapping
             if content_type in ['educational', 'academic'] and best_strategy_from_meta in ['conceptual', 'adaptive']:
                  suggested_strategy = best_strategy_from_meta
                  # print(f"  â¡ï¸ Meta-Learning ØªÙˆØµÙŠ Ø¨Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© '{suggested_strategy}' Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ© ÙˆÙ†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.") # Keep print optional
             elif content_type == 'technical' and best_strategy_from_meta in ['practical', 'adaptive', 'conceptual']: # Technical can sometimes benefit from conceptual
                  suggested_strategy = best_strategy_from_meta
                  # print(f"  â¡ï¸ Meta-Learning ØªÙˆØµÙŠ Ø¨Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© '{suggested_strategy}' Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ© ÙˆÙ†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.") # Keep print optional
             elif content_type == 'business' and best_strategy_from_meta == 'practical':
                  suggested_strategy = best_strategy_from_meta
                  # print(f"  â¡ï¸ Meta-Learning ØªÙˆØµÙŠ Ø¨Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© '{suggested_strategy}' Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ© ÙˆÙ†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.") # Keep print optional
             elif content_type == 'reference' and best_strategy_from_meta == 'conceptual': # For reference material, conceptual might be best
                  suggested_strategy = best_strategy_from_meta
                  # print(f"  â¡ï¸ Meta-Learning ØªÙˆØµÙŠ Ø¨Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© '{suggested_strategy}' Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ© ÙˆÙ†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.") # Keep print optional
             elif content_type == 'general' and best_strategy_from_meta in ['conceptual', 'practical']: # For general content, conceptual or practical might be good
                  suggested_strategy = best_strategy_from_meta
                  # print(f"  â¡ï¸ Meta-Learning ØªÙˆØµÙŠ Ø¨Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© '{suggested_strategy}' Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ© ÙˆÙ†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.") # Keep print optional
             else:
                 # If meta-learning strategy doesn't seem to fit content type, fall back to best meta strategy regardless
                 suggested_strategy = best_strategy_from_meta
                 # print(f"  â¡ï¸ Meta-Learning ØªÙˆØµÙŠ Ø¨Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© '{suggested_strategy}' Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ©.") # Keep print optional


        # Default to phase-based strategy if meta-learning doesn't provide a strong, relevant suggestion
        if suggested_strategy is None:
            if phase == 'foundation':
                suggested_strategy = 'conceptual'
                # print("  â¡ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ© Ù‚ÙˆÙŠØ© Ù…Ù† Meta-LearningØŒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù‡Ùˆ 'conceptual'.") # Keep print optional
            elif phase == 'application':
                suggested_strategy = 'practical'
                # print("  â¡ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ© Ù‚ÙˆÙŠØ© Ù…Ù† Meta-LearningØŒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù‡Ùˆ 'practical'.") # Keep print optional
            elif phase == 'advanced':
                suggested_strategy = 'adaptive'
                # print("  â¡ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ© Ù‚ÙˆÙŠØ© Ù…Ù† Meta-LearningØŒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù‡Ùˆ 'adaptive'.") # Keep print optional
            else:
                suggested_strategy = 'conceptual' # Fallback
                # print("  â¡ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙˆØµÙŠØ© Ù‚ÙˆÙŠØ© Ù…Ù† Meta-LearningØŒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø§Ù„Ø¹Ø§Ù… Ù‡Ùˆ 'conceptual'.") # Keep print optional


        # Further refine based on difficulty (simple example) - can override meta-learning if needed
        # If content is very hard, maybe adaptive is always preferred regardless of meta-learning patterns
        if avg_difficulty > 0.8: # Higher threshold for this override
             if 'adaptive' in self.teaching_strategies:
                  suggested_strategy = 'adaptive'
                  # print(f"  âš ï¸ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØµØ¹Ø¨ Ø¬Ø¯Ø§Ù‹ ({avg_difficulty:.2f})ØŒ ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¥Ù„Ù‰ '{suggested_strategy}'.") # Keep print optional
             elif 'conceptual' in self.teaching_strategies: # If no adaptive, maybe conceptual for very hard
                  suggested_strategy = 'conceptual'
                  # print(f"  âš ï¸ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØµØ¹Ø¨ Ø¬Ø¯Ø§Ù‹ ({avg_difficulty:.2f})ØŒ ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¥Ù„Ù‰ '{suggested_strategy}'.") # Keep print optional


        # print(f"  âœ… Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: '{suggested_strategy}'") # Keep print optional
        return suggested_strategy


    def _generate_response(self, prompt: str, max_tokens: int) -> str:
        # Check if using dummy model
        if isinstance(self.model, DummyModel):
            # print(f"Using DummyModel for response generation. Prompt: {prompt[:100]}...") # Keep print optional
            # Simulate a response based on prompt keywords or just a generic response
            if "Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©" in prompt or "ØªØ­Ù„ÙŠÙ„" in prompt:
                 return "Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:\n- ÙÙ‡Ù… Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n- Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚\n\nØ§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„ÙÙ‡Ù…:\n- Ù…ÙØ§Ù‡ÙŠÙ… Ø³Ø§Ø¨Ù‚Ø©\n\nØ±ÙˆØ§Ø¨Ø· Ù…Ø¹ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø£Ø®Ø±Ù‰:\n- Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø°Ø§Øª ØµÙ„Ø©"
            return "Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙˆÙ‡Ù…ÙŠØ© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬."

        # Original LLM call logic
        try:
            inputs = self.tokenizer(prompt, return_tensors="pt", padding=True, truncation=True, max_length=1024).to(self.device)
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_tokens,
                    num_return_sequences=1,
                    pad_token_id=self.tokenizer.eos_token_id,
                    no_repeat_ngram_size=3,
                    early_stopping=True,
                    temperature=0.7,
                    top_p=0.9
                )
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            if response.startswith(prompt):
                response = response[len(prompt):].strip()
            return response
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {e}"

    # Method for deep content analysis - Using simulation for this subtask
    def _deep_content_analysis(self, knowledge_unit: Dict) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù„ÙˆØ­Ø¯Ø© Ù…Ø¹Ø±ÙØ© ÙˆØ§Ø­Ø¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM (ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM ÙØ¹Ù„ÙŠ Ù‡Ù†Ø§)"""
        content = knowledge_unit['raw_text'] # Not needed for simulation

        # Simulate LLM analysis result structure, including slightly more varied prerequisites and connections
        filename = knowledge_unit.get('filename', 'Ø§Ù„Ù…Ø­ØªÙˆÙ‰')
        concepts = knowledge_unit.get('concepts', []) # Use all concepts extracted by FileProcessor

        simulated_analysis = {
            'analysis_text': f"Simulated analysis for {filename}",
            'teaching_objectives': [f"Understand {c}" for c in concepts[:3]], # Use top 3 concepts as objectives
            'prerequisites': [], # Start with empty, add based on filename for simulation
            'difficulty_points': [f"Complex concepts in {filename}"] if knowledge_unit.get('difficulty_level', 0) > 0.5 else [],
            'connections': [] # Start with empty, add based on filename for simulation
        }

        # Simulate prerequisites and connections based on filename patterns and actual extracted concepts
        # This helps ensure the simulated links can be matched to existing nodes.
        if 'advanced_ml_concepts' in filename.lower():
            # Try to use actual concepts from other files as prerequisites/connections
            # Look for specific concepts expected to be in other files
            if 'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ' in concepts: simulated_analysis['prerequisites'].append('Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ')
            if 'Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ' in concepts: simulated_analysis['prerequisites'].append('Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ')
            # Simulate dependency on intro files - use exact filenames processed
            simulated_analysis['prerequisites'].append('document_about_ai.txt')
            simulated_analysis['prerequisites'].append('notes_on_data_science.txt')
            # Connect to related concepts that might exist in the graph
            simulated_analysis['connections'].append('Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©') # Should exist as concept
            simulated_analysis['connections'].append('Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª') # Should exist as concept
        elif 'notes_on_data_science' in filename.lower():
             # Use actual concepts from this file or related ones
             if 'Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª' in concepts: simulated_analysis['prerequisites'].append('Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª') # Requires Data Science concept itself? Maybe basic stats
             simulated_analysis['prerequisites'].append('Ø§Ù„Ø¥Ø­ØµØ§Ø¡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ') # Simulate a generic prerequisite concept
             # Connect to related concepts/files
             simulated_analysis['connections'].append('Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ')
             simulated_analysis['connections'].append('Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ')
        elif 'document_about_ai' in filename.lower():
             if 'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ' in concepts: simulated_analysis['prerequisites'].append('Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ') # Requires AI concept itself?
             # Connect to related concepts
             simulated_analysis['connections'].append('Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©') # NLP
             simulated_analysis['connections'].append('Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©') # Computer Vision
             simulated_analysis['connections'].append('Ø§Ù„Ø±ÙˆØ¨ÙˆØªØ§Øª') # Robotics
             simulated_analysis['connections'].append('Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ') # AI relates to ML
        elif 'business_report_summary' in filename.lower():
             simulated_analysis['prerequisites'].append('Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©') # Simulate generic business concept
             simulated_analysis['connections'].append('Ø§Ù„ØªØ³ÙˆÙŠÙ‚')
             simulated_analysis['connections'].append('Ø§Ù„ØªÙ…ÙˆÙŠÙ„')
        # Add more specific simulations based on other file names and likely concepts
        elif 'code_generation_techniques' in filename.lower():
             simulated_analysis['prerequisites'].append('Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©') # Programming concept
             simulated_analysis['connections'].append('Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ÙŠ') # Generative AI concept
        elif 'reinforcement learning' in filename.lower() or 'rlagent' in filename.lower(): # Assuming related to advanced_ml_concepts and agent files
             if 'Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²' in concepts: simulated_analysis['prerequisites'].append('Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø²')
             simulated_analysis['prerequisites'].append('Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ') # ML is prerequisite for RL
             simulated_analysis['connections'].append('Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡') # Agents concept
        elif 'agent' in filename.lower() and 'herachitecal' in filename.lower(): # Assuming agent architecture
             simulated_analysis['prerequisites'].append('ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ') # AI Agents concept
             simulated_analysis['connections'].append('Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©') # Architecture concept
        elif 'generator' in filename.lower(): # Assuming code generation related
             simulated_analysis['prerequisites'].append('Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©')
             simulated_analysis['connections'].append('ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯')

        # Filter out prerequisites/connections that are the file itself or its own concepts (might happen with broad matches)
        simulated_analysis['prerequisites'] = [p for p in simulated_analysis['prerequisites'] if p != filename and p not in concepts]
        simulated_analysis['connections'] = [c for c in simulated_analysis['connections'] if c != filename and c not in concepts and c not in simulated_analysis['prerequisites']]

        # If using actual LLM, uncomment the following and implement parsing
        # analysis_prompt = f"""Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø®Ø¨ÙŠØ±. Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¹Ù…Ù‚:\n\nØ§Ù„Ù…Ø­ØªÙˆÙ‰: {content[:2000]}\n...\nØ§Ù„ØªØ­Ù„ÙŠÙ„:"""
        # analysis_response = self._generate_response(analysis_prompt, max_tokens=800)
        # simulated_analysis['analysis_text'] = analysis_response
        # simulated_analysis['teaching_objectives'] = self._extract_objectives(analysis_response) # Need to implement parsing
        # simulated_analysis['prerequisites'] = self._extract_prerequisites(analysis_response) # Need to implement parsing
        # simulated_analysis['difficulty_points'] = self._extract_difficulties(analysis_response) # Need to implement parsing
        # simulated_analysis['connections'] = self._extract_connections(analysis_response) # Need to implement parsing


        return simulated_analysis # Return simulated analysis


    def _extract_objectives(self, analysis_text: str) -> List[str]:
        # These extraction methods are only needed if using real LLM analysis output
        return []

    def _extract_prerequisites(self, analysis_text: str) -> List[str]:
        # These extraction methods are only needed if using real LLM analysis output
        return []

    def _extract_difficulties(self, analysis_text: str) -> List[str]:
        # These extraction methods are only needed if using real LLM analysis output
        return []

    def _extract_connections(self, analysis_text: str) -> List[str]:
        # These extraction methods are only needed if using real LLM analysis output
        return []

    def _estimate_learning_time(self, knowledge_unit: Dict) -> int:
        length_factor = len(knowledge_unit.get('raw_text', '')) / 500
        difficulty_factor = 1 + knowledge_unit.get('difficulty_level', 0) * 2
        estimated_time = int(length_factor * difficulty_factor)
        return max(estimated_time, 5)

    def _generate_step_objectives(self, knowledge_unit: Dict) -> List[str]:
        filename = knowledge_unit.get('filename', 'Ø§Ù„Ù…Ø­ØªÙˆÙ‰')
        concepts = knowledge_unit.get('concepts', [])[:3]
        objectives = [f"ÙÙ‡Ù… Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ {filename}"]
        if concepts:
             objectives.append(f"Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…: {', '.join(concepts)}")
        objectives.append(f"Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† {filename}")
        return objectives

    def _determine_training_priorities(self, analysis: Dict) -> List[Dict]:
        priorities = []
        for concept in analysis['concept_hierarchy'].get('core_concepts', []):
            priorities.append({'item': concept, 'type': 'concept', 'priority': 'Ø¹Ø§Ù„ÙŠØ©'})
        for step in analysis['learning_path']:
            if step['difficulty'] >= 0.7:
                priorities.append({'item': step['filename'], 'type': 'file', 'priority': 'Ø¹Ø§Ù„ÙŠØ© - ØµØ¹ÙˆØ¨Ø©'})
            if step.get('prerequisites'):
                 # Prioritize steps with complex prerequisites
                 priorities.append({'item': step['filename'], 'type': 'file', 'priority': f'Ù…ØªÙˆØ³Ø·Ø© - ÙŠØªØ·Ù„Ø¨: {", ".join(step["prerequisites"])}'})

        # Add priority for concepts/content with high failure rate from meta-learning (if any)
        struggling_content = self.meta_learning_insights.get('common_prerequisite_issues', {})
        for item, details in struggling_content.items():
             priorities.append({'item': item, 'type': 'content/concept', 'priority': f'Ø¹Ø§Ù„ÙŠØ© - Ø£Ø¸Ù‡Ø± Ø§Ù„Ø·Ù„Ø§Ø¨ ØµØ¹ÙˆØ¨Ø© ({details})'})


        return priorities

    # Define the method for performance analysis (Simulated)
    def _analyze_performance_logs(self):
        """Analyzes performance logs to update meta-learning insights (Simulated)."""
        # print("\nğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø³Ø¬Ù„Ø§Øª Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø·Ù„Ø§Ø¨ (Ù…Ø­Ø§ÙƒØ§Ø©)...") # Keep print optional

        logs = self.teaching_memory.get('strategy_performance_logs', [])
        if not logs:
            # print("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ø£Ø¯Ø§Ø¡ Ù„ØªØ­Ù„ÙŠÙ„Ù‡Ø§.") # Keep print optional
            return

        # Simulate Meta-Learning Insights based on some hardcoded logic or aggregated dummy data
        # This replaces actual complex analysis
        simulated_effectiveness = {
            'conceptual': 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: 0.85',
            'practical': 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: 0.60',
            'adaptive': 'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: 0.75'
        }
        simulated_issues = {} # Simulate no common issues for now
        simulated_sequencing = {'note': 'ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ø«Ù„Ù‰ ÙŠØªØ·Ù„Ø¨ ØªØªØ¨Ø¹ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ù„Ù„Ø·Ù„Ø§Ø¨ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬.'}
        simulated_student_summary = {'note': 'ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø·Ù„Ø§Ø¨ ÙŠØªØ·Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù„ÙØ§Øª ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØ³Ø¬Ù„Ø§Øª Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹.'}

        # You could add simple aggregation here if needed, e.g., count outcomes per strategy
        # For this subtask focused on KG, keeping this simple simulation is fine.


        self.meta_learning_insights['strategy_effectiveness_patterns'] = simulated_effectiveness
        self.meta_learning_insights['common_prerequisite_issues'] = simulated_issues
        self.meta_learning_insights['optimal_sequencing_patterns'] = simulated_sequencing
        self.meta_learning_insights['student_performance_summary'] = simulated_student_summary

        # print("âœ… ØªØ­Ù„ÙŠÙ„ Ø³Ø¬Ù„Ø§Øª Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø·Ù„Ø§Ø¨ (Ù…Ø­Ø§ÙƒØ§Ø©) Ù…ÙƒØªÙ…Ù„. ØªÙ… ØªØ­Ø¯ÙŠØ« meta_learning_insights.") # Keep print optional

    # New method for code generation
    def _generate_code(self, request: str, context: Dict[str, Any]) -> str:
        """
        Generates code based on a specific request and relevant context.

        Args:
            request (str): A description of the code to generate.
            context (Dict[str, Any]): Relevant knowledge from the graph or analysis,
                                       e.g., {'concepts': [...], 'chunks': [...], 'relationships': [...]}

        Returns:
            str: The generated code snippet or a descriptive message if generation fails.
        """
        print(f"\nğŸ’» Generating code based on request: '{request}'")
        # This is a placeholder. Actual implementation would involve:
        # 1. Crafting a detailed prompt for the LLM using the request and context.
        # 2. Calling the LLM (_generate_response).
        # 3. Parsing and potentially validating the LLM's response.
        # 4. Returning the generated code.

        # Simulate code generation based on the request
        if "RL agent" in request.lower() or "reinforcement learning" in request.lower():
            simulated_code = """
import numpy as np

class BasicRLAgent:
    def __init__(self, state_space_size, action_space_size):
        self.state_space_size = state_space_size
        self.action_space_size = action_space_size
        self.q_table = np.zeros((state_space_size, action_space_size))
        self.epsilon = 1.0  # Exploration rate
        self.alpha = 0.1    # Learning rate
        self.gamma = 0.99   # Discount factor

    def choose_action(self, state):
        if np.random.rand() < self.epsilon:
            return np.random.randint(self.action_space_size) # Explore
        else:
            return np.argmax(self.q_table[state, :]) # Exploit

    def learn(self, state, action, reward, next_state):
        predict = self.q_table[state, action]
        target = reward + self.gamma * np.max(self.q_table[next_state, :])
        self.q_table[state, action] += self.alpha * (target - predict)

# Example Usage (Simulated Environment)
# agent = BasicRLAgent(state_space_size=10, action_space_size=4)
# state = 0
# action = agent.choose_action(state)
# ... interact with environment, get reward, next_state ...
# agent.learn(state, action, reward, next_state)
"""
            print("âœ… Simulated RL Agent code generated.")
            return simulated_code
        elif "Python class" in request.lower():
            simulated_code = f"""
class MyGeneratedClass:
    def __init__(self, name):
        self.name = name
        print(f"Class {{self.name}} created.")

    def greet(self):
        return f"Hello from {{self.name}}!"

# Example Usage:
# my_instance = MyGeneratedClass("Test")
# print(my_instance.greet())
"""
            print("âœ… Simulated Python class code generated.")
            return simulated_code
        elif "algorithm" in request.lower():
            simulated_code = """
def quicksort(arr):
    if len(arr) <= 1:
        return arr
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    return quicksort(left) + middle + quicksort(right)

# Example Usage:
# my_list = [3, 6, 8, 10, 1, 2, 1]
# sorted_list = quicksort(my_list)
# print("Sorted list:", sorted_list)
"""
            print("âœ… Simulated algorithm code generated.")
            return simulated_code
        elif "equation" in request.lower() or "formula" in request.lower():
            simulated_code = """
# Pythagorean theorem: a^2 + b^2 = c^2
# In Python:
import math

def calculate_hypotenuse(a, b):
  return math.sqrt(a**2 + b**2)

# Example:
# side_a = 3
# side_b = 4
# hypotenuse = calculate_hypotenuse(side_a, side_b)
# print(f"Hypotenuse of a right triangle with sides {side_a} and {side_b} is {hypotenuse}")
"""
            print("âœ… Simulated equation/formula code generated.")
            return simulated_code
        elif "helper" in request.lower():
             simulated_code = """
def clean_text(text):
    # Basic text cleaning helper function
    text = text.lower()
    text = re.sub(r'[^a-z0-9\s]', '', text)
    return text.strip()

# Example Usage:
# dirty_string = "  Hello, World! 123 "
# cleaned_string = clean_text(dirty_string)
# print("Cleaned text:", cleaned_string)
"""
             print("âœ… Simulated helper function code generated.")
             return simulated_code
        elif "vector" in request.lower() or "matrix" in request.lower():
             simulated_code = """
import numpy as np

# Create a vector
vector = np.array([1, 2, 3])
print("Vector:", vector)

# Create a matrix
matrix = np.array([[1, 2], [3, 4], [5, 6]])
print("Matrix:\\n", matrix)

# Matrix multiplication
# matrix_A = np.array([[1, 2], [3, 4]])
# matrix_B = np.array([[5, 6], [7, 8]])
# result = np.dot(matrix_A, matrix_B)
# print("Matrix multiplication result:\\n", result)
"""
             print("âœ… Simulated vector/matrix code generated.")
             return simulated_code
        else:
            simulated_code = f"""
# Simulated code snippet for: {request}
# This is a generic placeholder.
# The actual code generation would be done by an LLM.

def generated_function():
    pass # Implement the logic here
"""
            print(f"âœ… Simulated generic code generated for '{request}'.")
            return simulated_code


# --- File Discovery and Processing ---
# Define the directory path
content_directory = '/content/'

# Get a list of all files and directories in the path
all_items = os.listdir(content_directory)

# Filter to include only files
all_files = [item for item in all_items if os.path.isfile(os.path.join(content_directory, item))]

# Create an empty dictionary to store file contents
uploaded_files = {}

# Instantiate the FileProcessor class
file_processor = FileProcessor()

# Iterate through the files, read their content, and process them
print(f"Scanning directory: {content_directory}")
for filename in all_files:
    file_path = os.path.join(content_directory, filename)
    try:
        # Read file content in binary mode
        with open(file_path, 'rb') as f:
            file_content_bytes = f.read()
        # print(f"âœ… Read file: {filename}") # Keep print optional
        # Process the file content using the FileProcessor
        # The FileProcessor's process_uploaded_files expects a dict of filename: content
        # We process files one by one here, so create a temporary dict for each file
        processed_unit = file_processor.process_uploaded_files({filename: file_content_bytes})
        # Merge the processed unit into the main extracted_knowledge dictionary
        # Ensure we only merge if processing was successful and returned a knowledge unit
        if processed_unit:
             if 'extracted_knowledge' not in locals():
                  extracted_knowledge = {} # Initialize if it doesn't exist
             extracted_knowledge.update(processed_unit)

    except Exception as e:
        print(f"âŒ Error reading or processing file {filename}: {e}")

print(f"\nFinished scanning and processing. Processed {len(extracted_knowledge) if 'extracted_knowledge' in locals() else 0} supported files.")


# --- Knowledge Graph Enrichment ---
# Instantiate the IntelligentTeacher class
# Check if extracted_knowledge is already available from the previous step
if 'extracted_knowledge' not in locals() or not extracted_knowledge:
     print("\nNo supported files were processed. Cannot build Knowledge Graph.")
else:
    teacher = IntelligentTeacher()

    # Populate the knowledge graph using the extracted_knowledge
    # This will also trigger deep content analysis (simulated) and the addition of advanced relationships
    teacher.populate_knowledge_graph(extracted_knowledge)

    # Print graph statistics
    print(f"\nKnowledge Graph Statistics:")
    print(f"Number of Nodes: {len(teacher.knowledge_graph.nodes)}")
    print(f"Number of Relationships: {len(teacher.knowledge_graph.relationships)}")

    # Query the graph for specific relationships to confirm they were added
    print("\nQuerying for 'requires_knowledge_from' relationships:")
    prereq_rels = teacher.knowledge_graph.get_relationships(rel_type='requires_knowledge_from')
    if prereq_rels:
        for rel in prereq_rels:
            source_node = teacher.knowledge_graph.get_node(rel.source_id)
            target_node = teacher.knowledge_graph.get_node(rel.target_id)
            if source_node and target_node:
                print(f"- {source_node.name} --({rel.type})--> {target_node.name} (Type: {target_node.type})")
    else:
        print("No 'requires_knowledge_from' relationships found.")

    print("\nQuerying for 'is_an_example_of' relationships:")
    example_rels = teacher.knowledge_graph.get_relationships(rel_type='is_an_example_of')
    if example_rels:
        for rel in example_rels:
            source_node = teacher.knowledge_graph.get_node(rel.source_id)
            target_node = teacher.knowledge_graph.get_node(rel.target_id)
            if source_node and target_node:
                print(f"- {source_node.name} --({rel.type})--> {target_node.name}")
    else:
        print("No 'is_an_example_of' relationships found.")

    print("\nQuerying for 'related_to' relationships:")
    related_rels = teacher.knowledge_graph.get_relationships(rel_type='related_to')
    if related_rels:
        for rel in related_rels:
            source_node = teacher.knowledge_graph.get_node(rel.source_id)
            target_node = teacher.knowledge_graph.get_node(rel.target_id)
            if source_node and target_node:
                print(f"- {source_node.name} --({rel.type})--> {target_node.name} (Type: {target_node.type})")
    else:
        print("No 'related_to' relationships found.")

    # --- Demonstrate Code Generation (Simulated) ---
    print("\n--- Demonstrating Simulated Code Generation ---")

    # Simulate a request for an RL agent
    rl_agent_request = "generate a Python class for a basic RL agent"
    # In a real scenario, we would gather relevant context (concepts, related files)
    # For this simulation, we'll just pass an empty context or relevant concepts
    rl_context = {'concepts': ['Reinforcement Learning', 'Agent', 'Q-Learning']}
    generated_rl_code = teacher._generate_code(rl_agent_request, rl_context)
    print(f"\nGenerated Code for RL Agent:\n```python\n{generated_rl_code}\n```")

    # Simulate a request for a helper function
    helper_request = "generate a Python helper function for text cleaning"
    helper_context = {'concepts': ['Text Processing', 'Cleaning Data']}
    generated_helper_code = teacher._generate_code(helper_request, helper_context)
    print(f"\nGenerated Code for Text Helper:\n```python\n{generated_helper_code}\n```")

    # Simulate a request for an algorithm
    algorithm_request = "generate a Python implementation of the quicksort algorithm"
    algorithm_context = {'concepts': ['Algorithm', 'Sorting']}
    generated_algorithm_code = teacher._generate_code(algorithm_request, algorithm_context)
    print(f"\nGenerated Code for Quicksort Algorithm:\n```python\n{generated_algorithm_code}\n```")

    # Simulate a request for a mathematical equation
    equation_request = "provide Python code for the Pythagorean theorem"
    equation_context = {'concepts': ['Geometry', 'Pythagorean Theorem']}
    generated_equation_code = teacher._generate_code(equation_request, equation_context)
    print(f"\nGenerated Code for Pythagorean Theorem:\n```python\n{generated_equation_code}\n```")

    # Simulate a request for a generic code snippet
    generic_request = "generate a basic loop iterating 10 times"
    generic_context = {}
    generated_generic_code = teacher._generate_code(generic_request, generic_context)
    print(f"\nGenerated Generic Code:\n```python\n{generated_generic_code}\n```")