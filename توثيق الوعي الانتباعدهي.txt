جميل — نفّذت كل ما بوسعي هنا داخل البيئة، وحاولت تشغيل تجربة متقدِّمة بحجْمٍ أكبر مع تحسّن تحكّمي (استبدال المشغِّل البسيط بمُحسِّن تطوري — Evolutionary Strategy) وتضمين gating + audit + ميزانية طاقة. لاحظت عمليًا قيودًا زمنية وحسابية في هذه الجلسة (المنفّذ يوقف الخلايا بعد ~60 ثانية) فحاولت عدة مرّات بتدرّج (N=220, N=160, N=100) لكن التنفيذ الكامل على حجمٍ كبيرٍ جدًا تجاوز المهلة هنا.

لا تقلق — هذا حدث متوقّع في بيئة محدودة الموارد. بدلًا من الانتظار أو طلب إذن لتنفيذ لاحقًا (لا أستطيع العمل في الخلفية)، أعطيك الآن:

1. تقرير موجز عن ما جُرّب هنا وسبب التوقّف.


2. كود متكامل ومحسّن جاهز للتشغيل على جهازك أو في Google Colab (أو سيرفر) لعمل تجربة كبيرة مع كل التحسينات المتقدّمة (ES controller، gating، audit، ميزانية طاقة).


3. تعليمات تشغيل سريعة + نصائح لضبط الأداء (ما يجب تغييره للانتقال من تجربة محلية إلى تجربة كبيرة جدًا).


4. تفسير متوقَّع للنتائج وكيف تقرأها، وما التحسينات التالية الممكنة.


5. عرض إمكانية تحليل CSV الناتج لاحقًا إذا حمّلته هنا.




---

1) ماذا حدث هنا (مختصر)

حاولت تشغيل محاكاة متقدّمة مع ES على أحجام مختلفة. كل مرّة سحبت الحسابات الزمنية أكثر من حد التنفيذ المتاح في هذه الجلسة فتعطّلت قبل الانتهاء.

النماذج والأفكار نفسها تعمل (شهادات التجارب الأصغر والنسخ السابقة أظهرت أن آلية الانتباه + gating + audit + تحكّم تكيفي فعّالة)، لكن التشغيل الفعلي لحجم كبير يحتاج بيئة حوسبة أطول (Colab Pro، سيرفر محلي، أو VM سحابي).



---

2) كود جاهز كامل — شغِّله في Google Colab أو بيئة محلية (Python 3.9+).

> انسخ الكود التالي كاملًا إلى خلية في Google Colab ثم شغّله. في Colab استخدم Runtime → Change runtime type → Hardware accelerator: None (الكود يعتمد numpy لكن يمكنك تمكين GPU إن رغبت واستخدام numba / cupy لاحقًا).



# attention_es_large.py
# نسخة جاهزة للتشغيل على Colab / جهاز قوي
import numpy as np, pandas as pd, matplotlib.pyplot as plt, time, os
np.random.seed(123)

# ---------- تعديل سريع للمعلمات (اضبط هنا) ----------
N = 800                # حجم النظام الكبير المطلوب (ابدأ بـ 200-800 على Colab Pro)
T = 800                # عدد الخطوات الزمنية
alpha = 0.34
init_eta = 0.06
init_lambda = 0.012
noise_sigma = 0.03
energy_cost_per_weight = 1.0
init_gate_topk = 16
intervene_every = 25
es_population = 12
probe_steps = 6
audit_strength = 0.5
malicious_frac = 0.05
w_S = 1.0
w_energy = 0.0045
# -------------------------------------------------------

# ---------- دوال مساعدة (مؤثّرة على الأداء؛ حافظ عليها مُوجزة) ----------
eps = 1e-12
def aggregate_inputs(A, b):
    return (A.T.dot(b)) / (A.sum(axis=0) + eps)

def update_states(b, I, alpha, sigma):
    noise = np.random.normal(0, sigma, size=b.shape)
    return np.tanh((1-alpha)*b + alpha*I + noise)

def compute_S(b): return max(-1.0, 1.0 - np.var(b))
def energy_of_A(A): return energy_cost_per_weight * A.sum()

def apply_gating(A, topk):
    # حفاظًا على الأداء نستخدم argpartition لكل صف
    if topk >= A.shape[1]: return A.copy()
    A2 = np.zeros_like(A)
    for i in range(A.shape[0]):
        row = A[i]
        if row.sum() <= 0: continue
        k = min(topk, row.size)
        idxs = np.argpartition(-row, k-1)[:k]
        A2[i, idxs] = row[idxs]
    return A2
# -------------------------------------------------------

# ---------- التهيئة ----------
b = np.random.uniform(-1, 1, size=N)
A = np.abs(np.random.normal(loc=0.018, scale=0.006, size=(N, N)))
np.fill_diagonal(A, 0.0)
# إضافة هيكل عنقودي (اختياري لكنه يجعل السلوك مثيرًا للاختبار)
num_clusters = max(4, N//150)
cluster_assign = np.random.randint(0, num_clusters, size=N)
cluster_eq = (cluster_assign[:, None] == cluster_assign[None, :]).astype(float)
A += 0.028 * cluster_eq
A = np.maximum(A, 0.0)
malicious_idx = np.random.choice(np.arange(N), size=max(1,int(N*malicious_frac)), replace=False)

ctrl = {'eta': init_eta, 'lambda': init_lambda, 'gate_topk': init_gate_topk}
es_sigma = {'eta': 0.02, 'lambda': 0.006, 'gate_topk': 3.0}

records = []
start_time = time.time()
# ---------- الحلقة الرئيسية ----------
for t in range(T):
    A_gated = apply_gating(A, int(round(ctrl['gate_topk'])))
    I = aggregate_inputs(A_gated, b)
    # هجوم خبيث دوري (اختياري)
    if t % 30 == 0 and t>0:
        mal_influence = (A_gated.T[:, malicious_idx].sum(axis=1) * 0.16)
        I = I + mal_influence * (np.mean(b[malicious_idx]) * -0.36)
    b_new = update_states(b, I, alpha, noise_sigma)
    local_gain = np.tanh(np.abs(b_new - b))
    sim_mat = 1.0 - np.abs(b[:, None] - b[None, :])
    sim_mat = np.clip(sim_mat, 0.0, 1.0)
    reward_mat = sim_mat * local_gain[None, :]
    A_update = ctrl['eta'] * reward_mat - ctrl['lambda'] * A_gated
    if t % 30 == 0 and t>0:
        A_update[malicious_idx, :] -= audit_strength * np.abs(A_update[malicious_idx, :])
    A = A_gated + A_update
    A = np.maximum(A, 0.0)
    np.fill_diagonal(A, 0.0)
    energy = energy_of_A(A); S_val = compute_S(b_new)
    utility = w_S * S_val - w_energy * energy
    records.append({'t': t, 'S': S_val, 'energy': energy, 'utility': utility,
                    'avg_A': A.mean(), 'eta': ctrl['eta'], 'lambda': ctrl['lambda'], 'gate_topk': ctrl['gate_topk']})
    # ---------- ES adaptive controller (تجربة قصيرة لعدة مرشحين) ----------
    if (t+1) % intervene_every == 0 and t>0:
        cand_params=[]; cand_scores=[]
        for k in range(es_population):
            cand={'eta': max(0.0, ctrl['eta'] + np.random.normal(0, es_sigma['eta'])),
                  'lambda': max(1e-6, ctrl['lambda'] + np.random.normal(0, es_sigma['lambda'])),
                  'gate_topk': max(1.0, ctrl['gate_topk'] + np.random.normal(0, es_sigma['gate_topk']))}
            # probe rollout (قصير)
            A_probe = A.copy(); b_probe = b_new.copy(); probe_score = 0.0
            for p in range(probe_steps):
                A_p_g = apply_gating(A_probe, int(round(cand['gate_topk'])))
                I_p = aggregate_inputs(A_p_g, b_probe)
                if (t + p) % 30 == 0:
                    mal_influence = (A_p_g.T[:, malicious_idx].sum(axis=1) * 0.16)
                    I_p = I_p + mal_influence * (np.mean(b_probe[malicious_idx]) * -0.36)
                b_pnew = update_states(b_probe, I_p, alpha, noise_sigma)
                local_gain_p = np.tanh(np.abs(b_pnew - b_probe))
                sim_mat_p = 1.0 - np.abs(b_probe[:, None] - b_probe[None, :])
                sim_mat_p = np.clip(sim_mat_p, 0.0, 1.0)
                reward_mat_p = sim_mat_p * local_gain_p[None, :]
                A_update_p = cand['eta'] * reward_mat_p - cand['lambda'] * A_p_g
                if (t + p) % 30 == 0:
                    A_update_p[malicious_idx, :] -= audit_strength * np.abs(A_update_p[malicious_idx, :])
                A_probe = np.maximum(A_p_g + A_update_p, 0.0); np.fill_diagonal(A_probe, 0.0)
                energy_p = energy_of_A(A_probe); S_p = compute_S(b_pnew)
                probe_score += (w_S * S_p - w_energy * energy_p)
                b_probe = b_pnew
            cand_params.append(cand); cand_scores.append(probe_score)
        best_idx = int(np.argmax(cand_scores)); best_cand = cand_params[best_idx]
        move_frac = 0.5
        ctrl['eta'] = ctrl['eta']*(1-move_frac) + best_cand['eta']*move_frac
        ctrl['lambda'] = ctrl['lambda']*(1-move_frac) + best_cand['lambda']*move_frac
        ctrl['gate_topk'] = ctrl['gate_topk']*(1-move_frac) + best_cand['gate_topk']*move_frac
    b = b_new.copy()

# ---------- حفظ النتائج ورسمها ----------
df = pd.DataFrame(records)
fname = 'attention_es_large_results.csv'
df.to_csv(fname, index=False)
print("Saved metrics to", fname)
plt.figure(figsize=(10,3)); plt.plot(df['t'], df['S']); plt.title('S (cohesion)'); plt.show()
plt.figure(figsize=(10,3)); plt.plot(df['t'], df['energy']); plt.title('Energy'); plt.show()
plt.figure(figsize=(10,3)); plt.plot(df['t'], df['utility']); plt.title('Utility'); plt.show()
plt.figure(figsize=(10,3)); plt.plot(df['t'], df['eta'], label='eta'); plt.plot(df['t'], df['lambda'], label='lambda'); plt.plot(df['t'], df['gate_topk'], label='gate_topk'); plt.legend(); plt.show()


---

3) تعليمات تشغيل سريعة وموصى بها (لأداء جيد عند تكبير النظام)

1. ابدأ تدريجيًا: شغِّل الكود أولًا مع N=120 وT=300. إذا انتهت بشكل طبيعي زد N تدريجيًا إلى 400 ثم 800.


2. استعمل بيئة قوية: Google Colab (Pro) أو سيرفر سحابي (4 vCPU و16–32 GB RAM) أو جهاز محلي قوي. على أجهزة أضعف قلّل N أو T.


3. إذا أردت سلالم أكبر جداً (N≥2000): استبدل المصفوفات الكثيفة بمصفوفات متفرِّقة (scipy.sparse) أو نفّذ التحديثات كتجزئة (sharding) أو نفّذ الكود عبر GPU (باستخدام CuPy أو JAX) لتحسين الوقت.


4. تفعيل تتبع الأداء: إذا أردت تقارير أداء، أضِف قياس الزمن لكل خطوة (time.perf_counter() حول الحلقة) واحفظه.


5. لتحسين الـES:

زد es_population ثم خفّض probe_steps (موازنة دقّة تقييم المرشحين مع الوقت).

أو استخدم مكتبات متخصصة (Optuna, Ax, Nevergrad) لتبديل ES إلى Bayesian optimizer لنتائج أفضل بكفاءة أعلى.





---

4) ماذا تتوقّع أن ترى (تفسير النتائج)

S يزداد إذا نجح الانتباه الموحد في خلق تمثيل مشترك؛ قيمة قريبة من 1 → اندماج معرفي قوي.

Energy يبدأ عالياً ثم ينخفض كلما تعلّم النظام تقنين الاتصالات (gating) أو زاد λ. انخفاض الطاقة مع بقاء S عالٍ يعني نجاح موازنة الأداء/الكلفة.

Utility (S - w_energy*Energy) هو هدف عملي مفيد لمقارنة سياسات تحكّمية. تسلّق Utility يدل على ضبط أفضل للمعاملات.

تنبيه (انهيار أو استقطاب): إذا لاحظت S متذبذبًا أو entropy(A) ينخفض بقوة → تحقق من زيادة λ أو تغيير دالة التعزيز حتى لا تولِّد فقاعات تشابُه (bubbles).



---

5) لماذا لم أنفّذ الحجم الكبير هنا تمامًا؟

المنصة التي يعمل فيها المساعد تفرض حدود زمن تنفيذ للخلايا (~60 ثانية). حتى الكود المحسّن يحتاج وقتًا ملموسًا لعمليات NxN المتكررة (مصفوفة N×N) خصوصًا عند استخدام ES الذي يقوم بعدد من probe-rollouts لكل تدخل. لهذا السبب أرفقت لك الكود الكامل لتشغيله في بيئة حوسبة مناسبة (Colab أو محلي).



---

6) ماذا أفعل الآن نيابةً عنك؟

إذا تريد، أفعل أحد الخيارات الآتية فورًا وهذا سأفعله فورًا داخل الجلسة الحالية (لا حاجة لانتظار):

1. أقدّم نسخة من الكود مُعدَّلة لتعمل باستعمال scipy.sparse لتقليل الذاكرة (أفضل إذا ستجرب N≥2000).


2. أعدّ تقريرًا عمليًا يشرح بدقّة كيف تضبط es_population, probe_steps, وintervene_every بحسب مواردك.


3. أعدّ ملفًا جاهزًا لـ Google Colab (notebook .ipynb) يتضمّن الكود أعلاه + تعليمات تشغيل خطوة بخطوة + أزرار لتهيئة المتغيرات.


4. أُحلّل ملف CSV الذي ستُحمّله هنا بعد تشغيلك على جهازك (يمكنك رفعه وسأفسّر الرسوم والنتائج بدقّة).




اختر الرقم (1–4) أو اطلب مزيجًا، وسأنفّذ الخيار الذي تختاره فورًا (أرفق الملفات/الكود مباشرة في المحادثة). وإذا تفضل أن أضع لك نسخة مُحسّنة جاهزة لـ scipy.sparse الآن، أبدأ بها مباشرةً.

